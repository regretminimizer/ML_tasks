{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HW 9 Lecture 10\n",
    "\n",
    "Apply classification metrics to MNIST classification problem \n",
    "- Accuracy (per class and general)\n",
    "- Precision (per class and general)\n",
    "- Recall (per class and general)\n",
    "- F1-score (per class and general)\n",
    "- Confusion matrix\n",
    "- Classification report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "# Params: 159010\n",
      "Train Epoch: 0 [0/60000 (0%)]\tLoss: 2.321859\n",
      "Train Epoch: 0 [1000/60000 (2%)]\tLoss: 1.826732\n",
      "Train Epoch: 0 [2000/60000 (3%)]\tLoss: 1.124478\n",
      "Train Epoch: 0 [3000/60000 (5%)]\tLoss: 0.933236\n",
      "Train Epoch: 0 [4000/60000 (7%)]\tLoss: 0.606949\n",
      "Train Epoch: 0 [5000/60000 (8%)]\tLoss: 0.387457\n",
      "Train Epoch: 0 [6000/60000 (10%)]\tLoss: 0.289856\n",
      "Train Epoch: 0 [7000/60000 (12%)]\tLoss: 0.537321\n",
      "Train Epoch: 0 [8000/60000 (13%)]\tLoss: 0.393156\n",
      "Train Epoch: 0 [9000/60000 (15%)]\tLoss: 0.832469\n",
      "Train Epoch: 0 [10000/60000 (17%)]\tLoss: 0.181064\n",
      "Train Epoch: 0 [11000/60000 (18%)]\tLoss: 0.052365\n",
      "Train Epoch: 0 [12000/60000 (20%)]\tLoss: 0.088084\n",
      "Train Epoch: 0 [13000/60000 (22%)]\tLoss: 0.446085\n",
      "Train Epoch: 0 [14000/60000 (23%)]\tLoss: 0.702687\n",
      "Train Epoch: 0 [15000/60000 (25%)]\tLoss: 0.076155\n",
      "Train Epoch: 0 [16000/60000 (27%)]\tLoss: 0.289117\n",
      "Train Epoch: 0 [17000/60000 (28%)]\tLoss: 0.196137\n",
      "Train Epoch: 0 [18000/60000 (30%)]\tLoss: 0.942845\n",
      "Train Epoch: 0 [19000/60000 (32%)]\tLoss: 0.256404\n",
      "Train Epoch: 0 [20000/60000 (33%)]\tLoss: 0.212651\n",
      "Train Epoch: 0 [21000/60000 (35%)]\tLoss: 0.380302\n",
      "Train Epoch: 0 [22000/60000 (37%)]\tLoss: 0.255351\n",
      "Train Epoch: 0 [23000/60000 (38%)]\tLoss: 0.343534\n",
      "Train Epoch: 0 [24000/60000 (40%)]\tLoss: 0.256216\n",
      "Train Epoch: 0 [25000/60000 (42%)]\tLoss: 0.194130\n",
      "Train Epoch: 0 [26000/60000 (43%)]\tLoss: 0.058293\n",
      "Train Epoch: 0 [27000/60000 (45%)]\tLoss: 0.154774\n",
      "Train Epoch: 0 [28000/60000 (47%)]\tLoss: 0.043548\n",
      "Train Epoch: 0 [29000/60000 (48%)]\tLoss: 0.373187\n",
      "Train Epoch: 0 [30000/60000 (50%)]\tLoss: 0.022429\n",
      "Train Epoch: 0 [31000/60000 (52%)]\tLoss: 0.270333\n",
      "Train Epoch: 0 [32000/60000 (53%)]\tLoss: 0.047934\n",
      "Train Epoch: 0 [33000/60000 (55%)]\tLoss: 0.463965\n",
      "Train Epoch: 0 [34000/60000 (57%)]\tLoss: 0.094449\n",
      "Train Epoch: 0 [35000/60000 (58%)]\tLoss: 0.045812\n",
      "Train Epoch: 0 [36000/60000 (60%)]\tLoss: 0.615096\n",
      "Train Epoch: 0 [37000/60000 (62%)]\tLoss: 0.072687\n",
      "Train Epoch: 0 [38000/60000 (63%)]\tLoss: 0.091849\n",
      "Train Epoch: 0 [39000/60000 (65%)]\tLoss: 0.242325\n",
      "Train Epoch: 0 [40000/60000 (67%)]\tLoss: 0.043178\n",
      "Train Epoch: 0 [41000/60000 (68%)]\tLoss: 0.495466\n",
      "Train Epoch: 0 [42000/60000 (70%)]\tLoss: 0.625647\n",
      "Train Epoch: 0 [43000/60000 (72%)]\tLoss: 0.170614\n",
      "Train Epoch: 0 [44000/60000 (73%)]\tLoss: 0.164209\n",
      "Train Epoch: 0 [45000/60000 (75%)]\tLoss: 0.248392\n",
      "Train Epoch: 0 [46000/60000 (77%)]\tLoss: 0.300264\n",
      "Train Epoch: 0 [47000/60000 (78%)]\tLoss: 0.242658\n",
      "Train Epoch: 0 [48000/60000 (80%)]\tLoss: 0.254633\n",
      "Train Epoch: 0 [49000/60000 (82%)]\tLoss: 0.697927\n",
      "Train Epoch: 0 [50000/60000 (83%)]\tLoss: 0.255571\n",
      "Train Epoch: 0 [51000/60000 (85%)]\tLoss: 0.170334\n",
      "Train Epoch: 0 [52000/60000 (87%)]\tLoss: 0.522113\n",
      "Train Epoch: 0 [53000/60000 (88%)]\tLoss: 0.177772\n",
      "Train Epoch: 0 [54000/60000 (90%)]\tLoss: 0.396118\n",
      "Train Epoch: 0 [55000/60000 (92%)]\tLoss: 0.164512\n",
      "Train Epoch: 0 [56000/60000 (93%)]\tLoss: 0.141790\n",
      "Train Epoch: 0 [57000/60000 (95%)]\tLoss: 0.333732\n",
      "Train Epoch: 0 [58000/60000 (97%)]\tLoss: 0.085211\n",
      "Train Epoch: 0 [59000/60000 (98%)]\tLoss: 0.100684\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 0.033769\n",
      "Train Epoch: 1 [1000/60000 (2%)]\tLoss: 0.173192\n",
      "Train Epoch: 1 [2000/60000 (3%)]\tLoss: 0.144707\n",
      "Train Epoch: 1 [3000/60000 (5%)]\tLoss: 0.056885\n",
      "Train Epoch: 1 [4000/60000 (7%)]\tLoss: 0.339019\n",
      "Train Epoch: 1 [5000/60000 (8%)]\tLoss: 0.164394\n",
      "Train Epoch: 1 [6000/60000 (10%)]\tLoss: 0.079139\n",
      "Train Epoch: 1 [7000/60000 (12%)]\tLoss: 0.492989\n",
      "Train Epoch: 1 [8000/60000 (13%)]\tLoss: 0.242773\n",
      "Train Epoch: 1 [9000/60000 (15%)]\tLoss: 0.530414\n",
      "Train Epoch: 1 [10000/60000 (17%)]\tLoss: 0.138570\n",
      "Train Epoch: 1 [11000/60000 (18%)]\tLoss: 0.022442\n",
      "Train Epoch: 1 [12000/60000 (20%)]\tLoss: 0.052649\n",
      "Train Epoch: 1 [13000/60000 (22%)]\tLoss: 0.298438\n",
      "Train Epoch: 1 [14000/60000 (23%)]\tLoss: 0.299651\n",
      "Train Epoch: 1 [15000/60000 (25%)]\tLoss: 0.026685\n",
      "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 0.096000\n",
      "Train Epoch: 1 [17000/60000 (28%)]\tLoss: 0.186190\n",
      "Train Epoch: 1 [18000/60000 (30%)]\tLoss: 0.727258\n",
      "Train Epoch: 1 [19000/60000 (32%)]\tLoss: 0.228594\n",
      "Train Epoch: 1 [20000/60000 (33%)]\tLoss: 0.105235\n",
      "Train Epoch: 1 [21000/60000 (35%)]\tLoss: 0.396463\n",
      "Train Epoch: 1 [22000/60000 (37%)]\tLoss: 0.184342\n",
      "Train Epoch: 1 [23000/60000 (38%)]\tLoss: 0.265323\n",
      "Train Epoch: 1 [24000/60000 (40%)]\tLoss: 0.071218\n",
      "Train Epoch: 1 [25000/60000 (42%)]\tLoss: 0.074988\n",
      "Train Epoch: 1 [26000/60000 (43%)]\tLoss: 0.027367\n",
      "Train Epoch: 1 [27000/60000 (45%)]\tLoss: 0.093103\n",
      "Train Epoch: 1 [28000/60000 (47%)]\tLoss: 0.026535\n",
      "Train Epoch: 1 [29000/60000 (48%)]\tLoss: 0.354557\n",
      "Train Epoch: 1 [30000/60000 (50%)]\tLoss: 0.012995\n",
      "Train Epoch: 1 [31000/60000 (52%)]\tLoss: 0.174859\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.042079\n",
      "Train Epoch: 1 [33000/60000 (55%)]\tLoss: 0.307287\n",
      "Train Epoch: 1 [34000/60000 (57%)]\tLoss: 0.027364\n",
      "Train Epoch: 1 [35000/60000 (58%)]\tLoss: 0.022450\n",
      "Train Epoch: 1 [36000/60000 (60%)]\tLoss: 0.457898\n",
      "Train Epoch: 1 [37000/60000 (62%)]\tLoss: 0.034322\n",
      "Train Epoch: 1 [38000/60000 (63%)]\tLoss: 0.042907\n",
      "Train Epoch: 1 [39000/60000 (65%)]\tLoss: 0.079466\n",
      "Train Epoch: 1 [40000/60000 (67%)]\tLoss: 0.030463\n",
      "Train Epoch: 1 [41000/60000 (68%)]\tLoss: 0.254551\n",
      "Train Epoch: 1 [42000/60000 (70%)]\tLoss: 0.475332\n",
      "Train Epoch: 1 [43000/60000 (72%)]\tLoss: 0.103274\n",
      "Train Epoch: 1 [44000/60000 (73%)]\tLoss: 0.077472\n",
      "Train Epoch: 1 [45000/60000 (75%)]\tLoss: 0.246001\n",
      "Train Epoch: 1 [46000/60000 (77%)]\tLoss: 0.156751\n",
      "Train Epoch: 1 [47000/60000 (78%)]\tLoss: 0.168053\n",
      "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.150656\n",
      "Train Epoch: 1 [49000/60000 (82%)]\tLoss: 0.762567\n",
      "Train Epoch: 1 [50000/60000 (83%)]\tLoss: 0.130743\n",
      "Train Epoch: 1 [51000/60000 (85%)]\tLoss: 0.094899\n",
      "Train Epoch: 1 [52000/60000 (87%)]\tLoss: 0.253671\n",
      "Train Epoch: 1 [53000/60000 (88%)]\tLoss: 0.096866\n",
      "Train Epoch: 1 [54000/60000 (90%)]\tLoss: 0.254489\n",
      "Train Epoch: 1 [55000/60000 (92%)]\tLoss: 0.066265\n",
      "Train Epoch: 1 [56000/60000 (93%)]\tLoss: 0.132375\n",
      "Train Epoch: 1 [57000/60000 (95%)]\tLoss: 0.274464\n",
      "Train Epoch: 1 [58000/60000 (97%)]\tLoss: 0.042960\n",
      "Train Epoch: 1 [59000/60000 (98%)]\tLoss: 0.026052\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.015251\n",
      "Train Epoch: 2 [1000/60000 (2%)]\tLoss: 0.105248\n",
      "Train Epoch: 2 [2000/60000 (3%)]\tLoss: 0.102254\n",
      "Train Epoch: 2 [3000/60000 (5%)]\tLoss: 0.034009\n",
      "Train Epoch: 2 [4000/60000 (7%)]\tLoss: 0.191399\n",
      "Train Epoch: 2 [5000/60000 (8%)]\tLoss: 0.135281\n",
      "Train Epoch: 2 [6000/60000 (10%)]\tLoss: 0.045668\n",
      "Train Epoch: 2 [7000/60000 (12%)]\tLoss: 0.431061\n",
      "Train Epoch: 2 [8000/60000 (13%)]\tLoss: 0.098321\n",
      "Train Epoch: 2 [9000/60000 (15%)]\tLoss: 0.353627\n",
      "Train Epoch: 2 [10000/60000 (17%)]\tLoss: 0.133727\n",
      "Train Epoch: 2 [11000/60000 (18%)]\tLoss: 0.021754\n",
      "Train Epoch: 2 [12000/60000 (20%)]\tLoss: 0.047559\n",
      "Train Epoch: 2 [13000/60000 (22%)]\tLoss: 0.225251\n",
      "Train Epoch: 2 [14000/60000 (23%)]\tLoss: 0.251207\n",
      "Train Epoch: 2 [15000/60000 (25%)]\tLoss: 0.031280\n",
      "Train Epoch: 2 [16000/60000 (27%)]\tLoss: 0.034320\n",
      "Train Epoch: 2 [17000/60000 (28%)]\tLoss: 0.155026\n",
      "Train Epoch: 2 [18000/60000 (30%)]\tLoss: 0.642497\n",
      "Train Epoch: 2 [19000/60000 (32%)]\tLoss: 0.266258\n",
      "Train Epoch: 2 [20000/60000 (33%)]\tLoss: 0.111276\n",
      "Train Epoch: 2 [21000/60000 (35%)]\tLoss: 0.281489\n",
      "Train Epoch: 2 [22000/60000 (37%)]\tLoss: 0.168337\n",
      "Train Epoch: 2 [23000/60000 (38%)]\tLoss: 0.236435\n",
      "Train Epoch: 2 [24000/60000 (40%)]\tLoss: 0.033369\n",
      "Train Epoch: 2 [25000/60000 (42%)]\tLoss: 0.039961\n",
      "Train Epoch: 2 [26000/60000 (43%)]\tLoss: 0.020453\n",
      "Train Epoch: 2 [27000/60000 (45%)]\tLoss: 0.053699\n",
      "Train Epoch: 2 [28000/60000 (47%)]\tLoss: 0.019896\n",
      "Train Epoch: 2 [29000/60000 (48%)]\tLoss: 0.339149\n",
      "Train Epoch: 2 [30000/60000 (50%)]\tLoss: 0.013575\n",
      "Train Epoch: 2 [31000/60000 (52%)]\tLoss: 0.090865\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.041166\n",
      "Train Epoch: 2 [33000/60000 (55%)]\tLoss: 0.212688\n",
      "Train Epoch: 2 [34000/60000 (57%)]\tLoss: 0.012851\n",
      "Train Epoch: 2 [35000/60000 (58%)]\tLoss: 0.011590\n",
      "Train Epoch: 2 [36000/60000 (60%)]\tLoss: 0.319668\n",
      "Train Epoch: 2 [37000/60000 (62%)]\tLoss: 0.020454\n",
      "Train Epoch: 2 [38000/60000 (63%)]\tLoss: 0.026861\n",
      "Train Epoch: 2 [39000/60000 (65%)]\tLoss: 0.037141\n",
      "Train Epoch: 2 [40000/60000 (67%)]\tLoss: 0.021744\n",
      "Train Epoch: 2 [41000/60000 (68%)]\tLoss: 0.114037\n",
      "Train Epoch: 2 [42000/60000 (70%)]\tLoss: 0.326037\n",
      "Train Epoch: 2 [43000/60000 (72%)]\tLoss: 0.081756\n",
      "Train Epoch: 2 [44000/60000 (73%)]\tLoss: 0.038870\n",
      "Train Epoch: 2 [45000/60000 (75%)]\tLoss: 0.214407\n",
      "Train Epoch: 2 [46000/60000 (77%)]\tLoss: 0.075728\n",
      "Train Epoch: 2 [47000/60000 (78%)]\tLoss: 0.141465\n",
      "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 0.101939\n",
      "Train Epoch: 2 [49000/60000 (82%)]\tLoss: 0.684409\n",
      "Train Epoch: 2 [50000/60000 (83%)]\tLoss: 0.077513\n",
      "Train Epoch: 2 [51000/60000 (85%)]\tLoss: 0.046188\n",
      "Train Epoch: 2 [52000/60000 (87%)]\tLoss: 0.104331\n",
      "Train Epoch: 2 [53000/60000 (88%)]\tLoss: 0.046921\n",
      "Train Epoch: 2 [54000/60000 (90%)]\tLoss: 0.124171\n",
      "Train Epoch: 2 [55000/60000 (92%)]\tLoss: 0.046858\n",
      "Train Epoch: 2 [56000/60000 (93%)]\tLoss: 0.125474\n",
      "Train Epoch: 2 [57000/60000 (95%)]\tLoss: 0.193141\n",
      "Train Epoch: 2 [58000/60000 (97%)]\tLoss: 0.024257\n",
      "Train Epoch: 2 [59000/60000 (98%)]\tLoss: 0.010457\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.009104\n",
      "Train Epoch: 3 [1000/60000 (2%)]\tLoss: 0.063976\n",
      "Train Epoch: 3 [2000/60000 (3%)]\tLoss: 0.073830\n",
      "Train Epoch: 3 [3000/60000 (5%)]\tLoss: 0.023938\n",
      "Train Epoch: 3 [4000/60000 (7%)]\tLoss: 0.113961\n",
      "Train Epoch: 3 [5000/60000 (8%)]\tLoss: 0.115855\n",
      "Train Epoch: 3 [6000/60000 (10%)]\tLoss: 0.029955\n",
      "Train Epoch: 3 [7000/60000 (12%)]\tLoss: 0.394093\n",
      "Train Epoch: 3 [8000/60000 (13%)]\tLoss: 0.058162\n",
      "Train Epoch: 3 [9000/60000 (15%)]\tLoss: 0.239853\n",
      "Train Epoch: 3 [10000/60000 (17%)]\tLoss: 0.132695\n",
      "Train Epoch: 3 [11000/60000 (18%)]\tLoss: 0.019603\n",
      "Train Epoch: 3 [12000/60000 (20%)]\tLoss: 0.035851\n",
      "Train Epoch: 3 [13000/60000 (22%)]\tLoss: 0.165244\n",
      "Train Epoch: 3 [14000/60000 (23%)]\tLoss: 0.251868\n",
      "Train Epoch: 3 [15000/60000 (25%)]\tLoss: 0.035930\n",
      "Train Epoch: 3 [16000/60000 (27%)]\tLoss: 0.014280\n",
      "Train Epoch: 3 [17000/60000 (28%)]\tLoss: 0.114848\n",
      "Train Epoch: 3 [18000/60000 (30%)]\tLoss: 0.533676\n",
      "Train Epoch: 3 [19000/60000 (32%)]\tLoss: 0.304970\n",
      "Train Epoch: 3 [20000/60000 (33%)]\tLoss: 0.114656\n",
      "Train Epoch: 3 [21000/60000 (35%)]\tLoss: 0.173766\n",
      "Train Epoch: 3 [22000/60000 (37%)]\tLoss: 0.152085\n",
      "Train Epoch: 3 [23000/60000 (38%)]\tLoss: 0.208389\n",
      "Train Epoch: 3 [24000/60000 (40%)]\tLoss: 0.021591\n",
      "Train Epoch: 3 [25000/60000 (42%)]\tLoss: 0.025677\n",
      "Train Epoch: 3 [26000/60000 (43%)]\tLoss: 0.018214\n",
      "Train Epoch: 3 [27000/60000 (45%)]\tLoss: 0.034747\n",
      "Train Epoch: 3 [28000/60000 (47%)]\tLoss: 0.015300\n",
      "Train Epoch: 3 [29000/60000 (48%)]\tLoss: 0.286134\n",
      "Train Epoch: 3 [30000/60000 (50%)]\tLoss: 0.016820\n",
      "Train Epoch: 3 [31000/60000 (52%)]\tLoss: 0.048469\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.033096\n",
      "Train Epoch: 3 [33000/60000 (55%)]\tLoss: 0.174959\n",
      "Train Epoch: 3 [34000/60000 (57%)]\tLoss: 0.008132\n",
      "Train Epoch: 3 [35000/60000 (58%)]\tLoss: 0.006566\n",
      "Train Epoch: 3 [36000/60000 (60%)]\tLoss: 0.236308\n",
      "Train Epoch: 3 [37000/60000 (62%)]\tLoss: 0.014773\n",
      "Train Epoch: 3 [38000/60000 (63%)]\tLoss: 0.020862\n",
      "Train Epoch: 3 [39000/60000 (65%)]\tLoss: 0.022013\n",
      "Train Epoch: 3 [40000/60000 (67%)]\tLoss: 0.015828\n",
      "Train Epoch: 3 [41000/60000 (68%)]\tLoss: 0.065846\n",
      "Train Epoch: 3 [42000/60000 (70%)]\tLoss: 0.206307\n",
      "Train Epoch: 3 [43000/60000 (72%)]\tLoss: 0.063845\n",
      "Train Epoch: 3 [44000/60000 (73%)]\tLoss: 0.022741\n",
      "Train Epoch: 3 [45000/60000 (75%)]\tLoss: 0.185220\n",
      "Train Epoch: 3 [46000/60000 (77%)]\tLoss: 0.041580\n",
      "Train Epoch: 3 [47000/60000 (78%)]\tLoss: 0.123754\n",
      "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 0.079609\n",
      "Train Epoch: 3 [49000/60000 (82%)]\tLoss: 0.571497\n",
      "Train Epoch: 3 [50000/60000 (83%)]\tLoss: 0.059503\n",
      "Train Epoch: 3 [51000/60000 (85%)]\tLoss: 0.025871\n",
      "Train Epoch: 3 [52000/60000 (87%)]\tLoss: 0.049822\n",
      "Train Epoch: 3 [53000/60000 (88%)]\tLoss: 0.024349\n",
      "Train Epoch: 3 [54000/60000 (90%)]\tLoss: 0.060977\n",
      "Train Epoch: 3 [55000/60000 (92%)]\tLoss: 0.036757\n",
      "Train Epoch: 3 [56000/60000 (93%)]\tLoss: 0.112749\n",
      "Train Epoch: 3 [57000/60000 (95%)]\tLoss: 0.130706\n",
      "Train Epoch: 3 [58000/60000 (97%)]\tLoss: 0.015781\n",
      "Train Epoch: 3 [59000/60000 (98%)]\tLoss: 0.005852\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.005989\n",
      "Train Epoch: 4 [1000/60000 (2%)]\tLoss: 0.040109\n",
      "Train Epoch: 4 [2000/60000 (3%)]\tLoss: 0.051410\n",
      "Train Epoch: 4 [3000/60000 (5%)]\tLoss: 0.016851\n",
      "Train Epoch: 4 [4000/60000 (7%)]\tLoss: 0.075571\n",
      "Train Epoch: 4 [5000/60000 (8%)]\tLoss: 0.112511\n",
      "Train Epoch: 4 [6000/60000 (10%)]\tLoss: 0.022766\n",
      "Train Epoch: 4 [7000/60000 (12%)]\tLoss: 0.359553\n",
      "Train Epoch: 4 [8000/60000 (13%)]\tLoss: 0.044398\n",
      "Train Epoch: 4 [9000/60000 (15%)]\tLoss: 0.179444\n",
      "Train Epoch: 4 [10000/60000 (17%)]\tLoss: 0.137879\n",
      "Train Epoch: 4 [11000/60000 (18%)]\tLoss: 0.018118\n",
      "Train Epoch: 4 [12000/60000 (20%)]\tLoss: 0.026816\n",
      "Train Epoch: 4 [13000/60000 (22%)]\tLoss: 0.128380\n",
      "Train Epoch: 4 [14000/60000 (23%)]\tLoss: 0.242811\n",
      "Train Epoch: 4 [15000/60000 (25%)]\tLoss: 0.033057\n",
      "Train Epoch: 4 [16000/60000 (27%)]\tLoss: 0.007742\n",
      "Train Epoch: 4 [17000/60000 (28%)]\tLoss: 0.086077\n",
      "Train Epoch: 4 [18000/60000 (30%)]\tLoss: 0.448475\n",
      "Train Epoch: 4 [19000/60000 (32%)]\tLoss: 0.334564\n",
      "Train Epoch: 4 [20000/60000 (33%)]\tLoss: 0.090503\n",
      "Train Epoch: 4 [21000/60000 (35%)]\tLoss: 0.111127\n",
      "Train Epoch: 4 [22000/60000 (37%)]\tLoss: 0.132505\n",
      "Train Epoch: 4 [23000/60000 (38%)]\tLoss: 0.176544\n",
      "Train Epoch: 4 [24000/60000 (40%)]\tLoss: 0.014602\n",
      "Train Epoch: 4 [25000/60000 (42%)]\tLoss: 0.020660\n",
      "Train Epoch: 4 [26000/60000 (43%)]\tLoss: 0.016296\n",
      "Train Epoch: 4 [27000/60000 (45%)]\tLoss: 0.023548\n",
      "Train Epoch: 4 [28000/60000 (47%)]\tLoss: 0.011559\n",
      "Train Epoch: 4 [29000/60000 (48%)]\tLoss: 0.219031\n",
      "Train Epoch: 4 [30000/60000 (50%)]\tLoss: 0.018100\n",
      "Train Epoch: 4 [31000/60000 (52%)]\tLoss: 0.029279\n",
      "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.026739\n",
      "Train Epoch: 4 [33000/60000 (55%)]\tLoss: 0.158517\n",
      "Train Epoch: 4 [34000/60000 (57%)]\tLoss: 0.006139\n",
      "Train Epoch: 4 [35000/60000 (58%)]\tLoss: 0.004256\n",
      "Train Epoch: 4 [36000/60000 (60%)]\tLoss: 0.183374\n",
      "Train Epoch: 4 [37000/60000 (62%)]\tLoss: 0.012406\n",
      "Train Epoch: 4 [38000/60000 (63%)]\tLoss: 0.018387\n",
      "Train Epoch: 4 [39000/60000 (65%)]\tLoss: 0.014960\n",
      "Train Epoch: 4 [40000/60000 (67%)]\tLoss: 0.011619\n",
      "Train Epoch: 4 [41000/60000 (68%)]\tLoss: 0.048270\n",
      "Train Epoch: 4 [42000/60000 (70%)]\tLoss: 0.125076\n",
      "Train Epoch: 4 [43000/60000 (72%)]\tLoss: 0.047990\n",
      "Train Epoch: 4 [44000/60000 (73%)]\tLoss: 0.014620\n",
      "Train Epoch: 4 [45000/60000 (75%)]\tLoss: 0.165263\n",
      "Train Epoch: 4 [46000/60000 (77%)]\tLoss: 0.026199\n",
      "Train Epoch: 4 [47000/60000 (78%)]\tLoss: 0.111338\n",
      "Train Epoch: 4 [48000/60000 (80%)]\tLoss: 0.065910\n",
      "Train Epoch: 4 [49000/60000 (82%)]\tLoss: 0.479465\n",
      "Train Epoch: 4 [50000/60000 (83%)]\tLoss: 0.052418\n",
      "Train Epoch: 4 [51000/60000 (85%)]\tLoss: 0.016940\n",
      "Train Epoch: 4 [52000/60000 (87%)]\tLoss: 0.030068\n",
      "Train Epoch: 4 [53000/60000 (88%)]\tLoss: 0.014263\n",
      "Train Epoch: 4 [54000/60000 (90%)]\tLoss: 0.038023\n",
      "Train Epoch: 4 [55000/60000 (92%)]\tLoss: 0.030316\n",
      "Train Epoch: 4 [56000/60000 (93%)]\tLoss: 0.096122\n",
      "Train Epoch: 4 [57000/60000 (95%)]\tLoss: 0.091672\n",
      "Train Epoch: 4 [58000/60000 (97%)]\tLoss: 0.011216\n",
      "Train Epoch: 4 [59000/60000 (98%)]\tLoss: 0.004019\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.004381\n",
      "Train Epoch: 5 [1000/60000 (2%)]\tLoss: 0.028407\n",
      "Train Epoch: 5 [2000/60000 (3%)]\tLoss: 0.036254\n",
      "Train Epoch: 5 [3000/60000 (5%)]\tLoss: 0.012653\n",
      "Train Epoch: 5 [4000/60000 (7%)]\tLoss: 0.055535\n",
      "Train Epoch: 5 [5000/60000 (8%)]\tLoss: 0.114442\n",
      "Train Epoch: 5 [6000/60000 (10%)]\tLoss: 0.018696\n",
      "Train Epoch: 5 [7000/60000 (12%)]\tLoss: 0.323245\n",
      "Train Epoch: 5 [8000/60000 (13%)]\tLoss: 0.036085\n",
      "Train Epoch: 5 [9000/60000 (15%)]\tLoss: 0.140722\n",
      "Train Epoch: 5 [10000/60000 (17%)]\tLoss: 0.137905\n",
      "Train Epoch: 5 [11000/60000 (18%)]\tLoss: 0.016789\n",
      "Train Epoch: 5 [12000/60000 (20%)]\tLoss: 0.021686\n",
      "Train Epoch: 5 [13000/60000 (22%)]\tLoss: 0.108090\n",
      "Train Epoch: 5 [14000/60000 (23%)]\tLoss: 0.218571\n",
      "Train Epoch: 5 [15000/60000 (25%)]\tLoss: 0.027434\n",
      "Train Epoch: 5 [16000/60000 (27%)]\tLoss: 0.005246\n",
      "Train Epoch: 5 [17000/60000 (28%)]\tLoss: 0.068290\n",
      "Train Epoch: 5 [18000/60000 (30%)]\tLoss: 0.393737\n",
      "Train Epoch: 5 [19000/60000 (32%)]\tLoss: 0.349870\n",
      "Train Epoch: 5 [20000/60000 (33%)]\tLoss: 0.063385\n",
      "Train Epoch: 5 [21000/60000 (35%)]\tLoss: 0.077447\n",
      "Train Epoch: 5 [22000/60000 (37%)]\tLoss: 0.110932\n",
      "Train Epoch: 5 [23000/60000 (38%)]\tLoss: 0.143942\n",
      "Train Epoch: 5 [24000/60000 (40%)]\tLoss: 0.010395\n",
      "Train Epoch: 5 [25000/60000 (42%)]\tLoss: 0.019646\n",
      "Train Epoch: 5 [26000/60000 (43%)]\tLoss: 0.013513\n",
      "Train Epoch: 5 [27000/60000 (45%)]\tLoss: 0.016723\n",
      "Train Epoch: 5 [28000/60000 (47%)]\tLoss: 0.008660\n",
      "Train Epoch: 5 [29000/60000 (48%)]\tLoss: 0.157812\n",
      "Train Epoch: 5 [30000/60000 (50%)]\tLoss: 0.016277\n",
      "Train Epoch: 5 [31000/60000 (52%)]\tLoss: 0.019501\n",
      "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.024246\n",
      "Train Epoch: 5 [33000/60000 (55%)]\tLoss: 0.141898\n",
      "Train Epoch: 5 [34000/60000 (57%)]\tLoss: 0.005019\n",
      "Train Epoch: 5 [35000/60000 (58%)]\tLoss: 0.002969\n",
      "Train Epoch: 5 [36000/60000 (60%)]\tLoss: 0.143742\n",
      "Train Epoch: 5 [37000/60000 (62%)]\tLoss: 0.010897\n",
      "Train Epoch: 5 [38000/60000 (63%)]\tLoss: 0.017497\n",
      "Train Epoch: 5 [39000/60000 (65%)]\tLoss: 0.011558\n",
      "Train Epoch: 5 [40000/60000 (67%)]\tLoss: 0.008656\n",
      "Train Epoch: 5 [41000/60000 (68%)]\tLoss: 0.039243\n",
      "Train Epoch: 5 [42000/60000 (70%)]\tLoss: 0.074543\n",
      "Train Epoch: 5 [43000/60000 (72%)]\tLoss: 0.035766\n",
      "Train Epoch: 5 [44000/60000 (73%)]\tLoss: 0.010226\n",
      "Train Epoch: 5 [45000/60000 (75%)]\tLoss: 0.152997\n",
      "Train Epoch: 5 [46000/60000 (77%)]\tLoss: 0.018272\n",
      "Train Epoch: 5 [47000/60000 (78%)]\tLoss: 0.101624\n",
      "Train Epoch: 5 [48000/60000 (80%)]\tLoss: 0.055147\n",
      "Train Epoch: 5 [49000/60000 (82%)]\tLoss: 0.405383\n",
      "Train Epoch: 5 [50000/60000 (83%)]\tLoss: 0.048723\n",
      "Train Epoch: 5 [51000/60000 (85%)]\tLoss: 0.012444\n",
      "Train Epoch: 5 [52000/60000 (87%)]\tLoss: 0.021705\n",
      "Train Epoch: 5 [53000/60000 (88%)]\tLoss: 0.009541\n",
      "Train Epoch: 5 [54000/60000 (90%)]\tLoss: 0.028132\n",
      "Train Epoch: 5 [55000/60000 (92%)]\tLoss: 0.026772\n",
      "Train Epoch: 5 [56000/60000 (93%)]\tLoss: 0.080560\n",
      "Train Epoch: 5 [57000/60000 (95%)]\tLoss: 0.066741\n",
      "Train Epoch: 5 [58000/60000 (97%)]\tLoss: 0.008496\n",
      "Train Epoch: 5 [59000/60000 (98%)]\tLoss: 0.003212\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.003443\n",
      "Train Epoch: 6 [1000/60000 (2%)]\tLoss: 0.021981\n",
      "Train Epoch: 6 [2000/60000 (3%)]\tLoss: 0.026808\n",
      "Train Epoch: 6 [3000/60000 (5%)]\tLoss: 0.010329\n",
      "Train Epoch: 6 [4000/60000 (7%)]\tLoss: 0.044025\n",
      "Train Epoch: 6 [5000/60000 (8%)]\tLoss: 0.115110\n",
      "Train Epoch: 6 [6000/60000 (10%)]\tLoss: 0.016267\n",
      "Train Epoch: 6 [7000/60000 (12%)]\tLoss: 0.287394\n",
      "Train Epoch: 6 [8000/60000 (13%)]\tLoss: 0.030978\n",
      "Train Epoch: 6 [9000/60000 (15%)]\tLoss: 0.112918\n",
      "Train Epoch: 6 [10000/60000 (17%)]\tLoss: 0.129880\n",
      "Train Epoch: 6 [11000/60000 (18%)]\tLoss: 0.014575\n",
      "Train Epoch: 6 [12000/60000 (20%)]\tLoss: 0.018895\n",
      "Train Epoch: 6 [13000/60000 (22%)]\tLoss: 0.097398\n",
      "Train Epoch: 6 [14000/60000 (23%)]\tLoss: 0.186922\n",
      "Train Epoch: 6 [15000/60000 (25%)]\tLoss: 0.021925\n",
      "Train Epoch: 6 [16000/60000 (27%)]\tLoss: 0.003982\n",
      "Train Epoch: 6 [17000/60000 (28%)]\tLoss: 0.056223\n",
      "Train Epoch: 6 [18000/60000 (30%)]\tLoss: 0.352487\n",
      "Train Epoch: 6 [19000/60000 (32%)]\tLoss: 0.348786\n",
      "Train Epoch: 6 [20000/60000 (33%)]\tLoss: 0.044460\n",
      "Train Epoch: 6 [21000/60000 (35%)]\tLoss: 0.057681\n",
      "Train Epoch: 6 [22000/60000 (37%)]\tLoss: 0.090381\n",
      "Train Epoch: 6 [23000/60000 (38%)]\tLoss: 0.115326\n",
      "Train Epoch: 6 [24000/60000 (40%)]\tLoss: 0.007759\n",
      "Train Epoch: 6 [25000/60000 (42%)]\tLoss: 0.018792\n",
      "Train Epoch: 6 [26000/60000 (43%)]\tLoss: 0.010632\n",
      "Train Epoch: 6 [27000/60000 (45%)]\tLoss: 0.012586\n",
      "Train Epoch: 6 [28000/60000 (47%)]\tLoss: 0.006542\n",
      "Train Epoch: 6 [29000/60000 (48%)]\tLoss: 0.111006\n",
      "Train Epoch: 6 [30000/60000 (50%)]\tLoss: 0.013224\n",
      "Train Epoch: 6 [31000/60000 (52%)]\tLoss: 0.013794\n",
      "Train Epoch: 6 [32000/60000 (53%)]\tLoss: 0.024276\n",
      "Train Epoch: 6 [33000/60000 (55%)]\tLoss: 0.120936\n",
      "Train Epoch: 6 [34000/60000 (57%)]\tLoss: 0.004220\n",
      "Train Epoch: 6 [35000/60000 (58%)]\tLoss: 0.002160\n",
      "Train Epoch: 6 [36000/60000 (60%)]\tLoss: 0.113819\n",
      "Train Epoch: 6 [37000/60000 (62%)]\tLoss: 0.009625\n",
      "Train Epoch: 6 [38000/60000 (63%)]\tLoss: 0.017241\n",
      "Train Epoch: 6 [39000/60000 (65%)]\tLoss: 0.009508\n",
      "Train Epoch: 6 [40000/60000 (67%)]\tLoss: 0.006752\n",
      "Train Epoch: 6 [41000/60000 (68%)]\tLoss: 0.032792\n",
      "Train Epoch: 6 [42000/60000 (70%)]\tLoss: 0.045451\n",
      "Train Epoch: 6 [43000/60000 (72%)]\tLoss: 0.027075\n",
      "Train Epoch: 6 [44000/60000 (73%)]\tLoss: 0.007630\n",
      "Train Epoch: 6 [45000/60000 (75%)]\tLoss: 0.141327\n",
      "Train Epoch: 6 [46000/60000 (77%)]\tLoss: 0.013751\n",
      "Train Epoch: 6 [47000/60000 (78%)]\tLoss: 0.091604\n",
      "Train Epoch: 6 [48000/60000 (80%)]\tLoss: 0.044964\n",
      "Train Epoch: 6 [49000/60000 (82%)]\tLoss: 0.341983\n",
      "Train Epoch: 6 [50000/60000 (83%)]\tLoss: 0.046519\n",
      "Train Epoch: 6 [51000/60000 (85%)]\tLoss: 0.009852\n",
      "Train Epoch: 6 [52000/60000 (87%)]\tLoss: 0.017228\n",
      "Train Epoch: 6 [53000/60000 (88%)]\tLoss: 0.007101\n",
      "Train Epoch: 6 [54000/60000 (90%)]\tLoss: 0.022143\n",
      "Train Epoch: 6 [55000/60000 (92%)]\tLoss: 0.023946\n",
      "Train Epoch: 6 [56000/60000 (93%)]\tLoss: 0.069635\n",
      "Train Epoch: 6 [57000/60000 (95%)]\tLoss: 0.050549\n",
      "Train Epoch: 6 [58000/60000 (97%)]\tLoss: 0.006770\n",
      "Train Epoch: 6 [59000/60000 (98%)]\tLoss: 0.002728\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.002833\n",
      "Train Epoch: 7 [1000/60000 (2%)]\tLoss: 0.017491\n",
      "Train Epoch: 7 [2000/60000 (3%)]\tLoss: 0.020718\n",
      "Train Epoch: 7 [3000/60000 (5%)]\tLoss: 0.008868\n",
      "Train Epoch: 7 [4000/60000 (7%)]\tLoss: 0.036227\n",
      "Train Epoch: 7 [5000/60000 (8%)]\tLoss: 0.116282\n",
      "Train Epoch: 7 [6000/60000 (10%)]\tLoss: 0.014845\n",
      "Train Epoch: 7 [7000/60000 (12%)]\tLoss: 0.255228\n",
      "Train Epoch: 7 [8000/60000 (13%)]\tLoss: 0.027840\n",
      "Train Epoch: 7 [9000/60000 (15%)]\tLoss: 0.093569\n",
      "Train Epoch: 7 [10000/60000 (17%)]\tLoss: 0.116951\n",
      "Train Epoch: 7 [11000/60000 (18%)]\tLoss: 0.012089\n",
      "Train Epoch: 7 [12000/60000 (20%)]\tLoss: 0.017258\n",
      "Train Epoch: 7 [13000/60000 (22%)]\tLoss: 0.091792\n",
      "Train Epoch: 7 [14000/60000 (23%)]\tLoss: 0.155813\n",
      "Train Epoch: 7 [15000/60000 (25%)]\tLoss: 0.017149\n",
      "Train Epoch: 7 [16000/60000 (27%)]\tLoss: 0.003176\n",
      "Train Epoch: 7 [17000/60000 (28%)]\tLoss: 0.047484\n",
      "Train Epoch: 7 [18000/60000 (30%)]\tLoss: 0.313221\n",
      "Train Epoch: 7 [19000/60000 (32%)]\tLoss: 0.332455\n",
      "Train Epoch: 7 [20000/60000 (33%)]\tLoss: 0.032984\n",
      "Train Epoch: 7 [21000/60000 (35%)]\tLoss: 0.045109\n",
      "Train Epoch: 7 [22000/60000 (37%)]\tLoss: 0.074201\n",
      "Train Epoch: 7 [23000/60000 (38%)]\tLoss: 0.091339\n",
      "Train Epoch: 7 [24000/60000 (40%)]\tLoss: 0.005957\n",
      "Train Epoch: 7 [25000/60000 (42%)]\tLoss: 0.016805\n",
      "Train Epoch: 7 [26000/60000 (43%)]\tLoss: 0.008260\n",
      "Train Epoch: 7 [27000/60000 (45%)]\tLoss: 0.010001\n",
      "Train Epoch: 7 [28000/60000 (47%)]\tLoss: 0.004974\n",
      "Train Epoch: 7 [29000/60000 (48%)]\tLoss: 0.079148\n",
      "Train Epoch: 7 [30000/60000 (50%)]\tLoss: 0.010267\n",
      "Train Epoch: 7 [31000/60000 (52%)]\tLoss: 0.010073\n",
      "Train Epoch: 7 [32000/60000 (53%)]\tLoss: 0.025730\n",
      "Train Epoch: 7 [33000/60000 (55%)]\tLoss: 0.098461\n",
      "Train Epoch: 7 [34000/60000 (57%)]\tLoss: 0.003592\n",
      "Train Epoch: 7 [35000/60000 (58%)]\tLoss: 0.001620\n",
      "Train Epoch: 7 [36000/60000 (60%)]\tLoss: 0.091853\n",
      "Train Epoch: 7 [37000/60000 (62%)]\tLoss: 0.008526\n",
      "Train Epoch: 7 [38000/60000 (63%)]\tLoss: 0.017062\n",
      "Train Epoch: 7 [39000/60000 (65%)]\tLoss: 0.007960\n",
      "Train Epoch: 7 [40000/60000 (67%)]\tLoss: 0.005535\n",
      "Train Epoch: 7 [41000/60000 (68%)]\tLoss: 0.027405\n",
      "Train Epoch: 7 [42000/60000 (70%)]\tLoss: 0.029273\n",
      "Train Epoch: 7 [43000/60000 (72%)]\tLoss: 0.021214\n",
      "Train Epoch: 7 [44000/60000 (73%)]\tLoss: 0.005999\n",
      "Train Epoch: 7 [45000/60000 (75%)]\tLoss: 0.127462\n",
      "Train Epoch: 7 [46000/60000 (77%)]\tLoss: 0.010843\n",
      "Train Epoch: 7 [47000/60000 (78%)]\tLoss: 0.080518\n",
      "Train Epoch: 7 [48000/60000 (80%)]\tLoss: 0.035959\n",
      "Train Epoch: 7 [49000/60000 (82%)]\tLoss: 0.287628\n",
      "Train Epoch: 7 [50000/60000 (83%)]\tLoss: 0.045380\n",
      "Train Epoch: 7 [51000/60000 (85%)]\tLoss: 0.008186\n",
      "Train Epoch: 7 [52000/60000 (87%)]\tLoss: 0.014381\n",
      "Train Epoch: 7 [53000/60000 (88%)]\tLoss: 0.005690\n",
      "Train Epoch: 7 [54000/60000 (90%)]\tLoss: 0.018078\n",
      "Train Epoch: 7 [55000/60000 (92%)]\tLoss: 0.020846\n",
      "Train Epoch: 7 [56000/60000 (93%)]\tLoss: 0.062178\n",
      "Train Epoch: 7 [57000/60000 (95%)]\tLoss: 0.039310\n",
      "Train Epoch: 7 [58000/60000 (97%)]\tLoss: 0.005631\n",
      "Train Epoch: 7 [59000/60000 (98%)]\tLoss: 0.002344\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.002395\n",
      "Train Epoch: 8 [1000/60000 (2%)]\tLoss: 0.014012\n",
      "Train Epoch: 8 [2000/60000 (3%)]\tLoss: 0.016681\n",
      "Train Epoch: 8 [3000/60000 (5%)]\tLoss: 0.007781\n",
      "Train Epoch: 8 [4000/60000 (7%)]\tLoss: 0.030402\n",
      "Train Epoch: 8 [5000/60000 (8%)]\tLoss: 0.118985\n",
      "Train Epoch: 8 [6000/60000 (10%)]\tLoss: 0.013849\n",
      "Train Epoch: 8 [7000/60000 (12%)]\tLoss: 0.228229\n",
      "Train Epoch: 8 [8000/60000 (13%)]\tLoss: 0.025738\n",
      "Train Epoch: 8 [9000/60000 (15%)]\tLoss: 0.079794\n",
      "Train Epoch: 8 [10000/60000 (17%)]\tLoss: 0.102904\n",
      "Train Epoch: 8 [11000/60000 (18%)]\tLoss: 0.009929\n",
      "Train Epoch: 8 [12000/60000 (20%)]\tLoss: 0.016278\n",
      "Train Epoch: 8 [13000/60000 (22%)]\tLoss: 0.088626\n",
      "Train Epoch: 8 [14000/60000 (23%)]\tLoss: 0.128778\n",
      "Train Epoch: 8 [15000/60000 (25%)]\tLoss: 0.013273\n",
      "Train Epoch: 8 [16000/60000 (27%)]\tLoss: 0.002593\n",
      "Train Epoch: 8 [17000/60000 (28%)]\tLoss: 0.041284\n",
      "Train Epoch: 8 [18000/60000 (30%)]\tLoss: 0.273437\n",
      "Train Epoch: 8 [19000/60000 (32%)]\tLoss: 0.304876\n",
      "Train Epoch: 8 [20000/60000 (33%)]\tLoss: 0.025886\n",
      "Train Epoch: 8 [21000/60000 (35%)]\tLoss: 0.036528\n",
      "Train Epoch: 8 [22000/60000 (37%)]\tLoss: 0.062698\n",
      "Train Epoch: 8 [23000/60000 (38%)]\tLoss: 0.071756\n",
      "Train Epoch: 8 [24000/60000 (40%)]\tLoss: 0.004684\n",
      "Train Epoch: 8 [25000/60000 (42%)]\tLoss: 0.014129\n",
      "Train Epoch: 8 [26000/60000 (43%)]\tLoss: 0.006433\n",
      "Train Epoch: 8 [27000/60000 (45%)]\tLoss: 0.008395\n",
      "Train Epoch: 8 [28000/60000 (47%)]\tLoss: 0.003784\n",
      "Train Epoch: 8 [29000/60000 (48%)]\tLoss: 0.058445\n",
      "Train Epoch: 8 [30000/60000 (50%)]\tLoss: 0.007931\n",
      "Train Epoch: 8 [31000/60000 (52%)]\tLoss: 0.007563\n",
      "Train Epoch: 8 [32000/60000 (53%)]\tLoss: 0.027873\n",
      "Train Epoch: 8 [33000/60000 (55%)]\tLoss: 0.077415\n",
      "Train Epoch: 8 [34000/60000 (57%)]\tLoss: 0.003093\n",
      "Train Epoch: 8 [35000/60000 (58%)]\tLoss: 0.001250\n",
      "Train Epoch: 8 [36000/60000 (60%)]\tLoss: 0.076187\n",
      "Train Epoch: 8 [37000/60000 (62%)]\tLoss: 0.007534\n",
      "Train Epoch: 8 [38000/60000 (63%)]\tLoss: 0.016804\n",
      "Train Epoch: 8 [39000/60000 (65%)]\tLoss: 0.006759\n",
      "Train Epoch: 8 [40000/60000 (67%)]\tLoss: 0.004705\n",
      "Train Epoch: 8 [41000/60000 (68%)]\tLoss: 0.022801\n",
      "Train Epoch: 8 [42000/60000 (70%)]\tLoss: 0.020027\n",
      "Train Epoch: 8 [43000/60000 (72%)]\tLoss: 0.017255\n",
      "Train Epoch: 8 [44000/60000 (73%)]\tLoss: 0.004930\n",
      "Train Epoch: 8 [45000/60000 (75%)]\tLoss: 0.112017\n",
      "Train Epoch: 8 [46000/60000 (77%)]\tLoss: 0.008780\n",
      "Train Epoch: 8 [47000/60000 (78%)]\tLoss: 0.069120\n",
      "Train Epoch: 8 [48000/60000 (80%)]\tLoss: 0.028610\n",
      "Train Epoch: 8 [49000/60000 (82%)]\tLoss: 0.241989\n",
      "Train Epoch: 8 [50000/60000 (83%)]\tLoss: 0.045254\n",
      "Train Epoch: 8 [51000/60000 (85%)]\tLoss: 0.006989\n",
      "Train Epoch: 8 [52000/60000 (87%)]\tLoss: 0.012445\n",
      "Train Epoch: 8 [53000/60000 (88%)]\tLoss: 0.004790\n",
      "Train Epoch: 8 [54000/60000 (90%)]\tLoss: 0.015306\n",
      "Train Epoch: 8 [55000/60000 (92%)]\tLoss: 0.017460\n",
      "Train Epoch: 8 [56000/60000 (93%)]\tLoss: 0.056527\n",
      "Train Epoch: 8 [57000/60000 (95%)]\tLoss: 0.031252\n",
      "Train Epoch: 8 [58000/60000 (97%)]\tLoss: 0.004843\n",
      "Train Epoch: 8 [59000/60000 (98%)]\tLoss: 0.002008\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.002048\n",
      "Train Epoch: 9 [1000/60000 (2%)]\tLoss: 0.011288\n",
      "Train Epoch: 9 [2000/60000 (3%)]\tLoss: 0.014020\n",
      "Train Epoch: 9 [3000/60000 (5%)]\tLoss: 0.006912\n",
      "Train Epoch: 9 [4000/60000 (7%)]\tLoss: 0.025985\n",
      "Train Epoch: 9 [5000/60000 (8%)]\tLoss: 0.122244\n",
      "Train Epoch: 9 [6000/60000 (10%)]\tLoss: 0.012905\n",
      "Train Epoch: 9 [7000/60000 (12%)]\tLoss: 0.205899\n",
      "Train Epoch: 9 [8000/60000 (13%)]\tLoss: 0.024086\n",
      "Train Epoch: 9 [9000/60000 (15%)]\tLoss: 0.069681\n",
      "Train Epoch: 9 [10000/60000 (17%)]\tLoss: 0.089795\n",
      "Train Epoch: 9 [11000/60000 (18%)]\tLoss: 0.008262\n",
      "Train Epoch: 9 [12000/60000 (20%)]\tLoss: 0.015774\n",
      "Train Epoch: 9 [13000/60000 (22%)]\tLoss: 0.086397\n",
      "Train Epoch: 9 [14000/60000 (23%)]\tLoss: 0.107212\n",
      "Train Epoch: 9 [15000/60000 (25%)]\tLoss: 0.010233\n",
      "Train Epoch: 9 [16000/60000 (27%)]\tLoss: 0.002151\n",
      "Train Epoch: 9 [17000/60000 (28%)]\tLoss: 0.037022\n",
      "Train Epoch: 9 [18000/60000 (30%)]\tLoss: 0.235378\n",
      "Train Epoch: 9 [19000/60000 (32%)]\tLoss: 0.271309\n",
      "Train Epoch: 9 [20000/60000 (33%)]\tLoss: 0.021152\n",
      "Train Epoch: 9 [21000/60000 (35%)]\tLoss: 0.030261\n",
      "Train Epoch: 9 [22000/60000 (37%)]\tLoss: 0.054368\n",
      "Train Epoch: 9 [23000/60000 (38%)]\tLoss: 0.056395\n",
      "Train Epoch: 9 [24000/60000 (40%)]\tLoss: 0.003794\n",
      "Train Epoch: 9 [25000/60000 (42%)]\tLoss: 0.011467\n",
      "Train Epoch: 9 [26000/60000 (43%)]\tLoss: 0.005049\n",
      "Train Epoch: 9 [27000/60000 (45%)]\tLoss: 0.007422\n",
      "Train Epoch: 9 [28000/60000 (47%)]\tLoss: 0.002887\n",
      "Train Epoch: 9 [29000/60000 (48%)]\tLoss: 0.044781\n",
      "Train Epoch: 9 [30000/60000 (50%)]\tLoss: 0.006244\n",
      "Train Epoch: 9 [31000/60000 (52%)]\tLoss: 0.005862\n",
      "Train Epoch: 9 [32000/60000 (53%)]\tLoss: 0.030184\n",
      "Train Epoch: 9 [33000/60000 (55%)]\tLoss: 0.059558\n",
      "Train Epoch: 9 [34000/60000 (57%)]\tLoss: 0.002700\n",
      "Train Epoch: 9 [35000/60000 (58%)]\tLoss: 0.000993\n",
      "Train Epoch: 9 [36000/60000 (60%)]\tLoss: 0.065028\n",
      "Train Epoch: 9 [37000/60000 (62%)]\tLoss: 0.006604\n",
      "Train Epoch: 9 [38000/60000 (63%)]\tLoss: 0.016510\n",
      "Train Epoch: 9 [39000/60000 (65%)]\tLoss: 0.005844\n",
      "Train Epoch: 9 [40000/60000 (67%)]\tLoss: 0.004083\n",
      "Train Epoch: 9 [41000/60000 (68%)]\tLoss: 0.018963\n",
      "Train Epoch: 9 [42000/60000 (70%)]\tLoss: 0.014387\n",
      "Train Epoch: 9 [43000/60000 (72%)]\tLoss: 0.014428\n",
      "Train Epoch: 9 [44000/60000 (73%)]\tLoss: 0.004194\n",
      "Train Epoch: 9 [45000/60000 (75%)]\tLoss: 0.096543\n",
      "Train Epoch: 9 [46000/60000 (77%)]\tLoss: 0.007244\n",
      "Train Epoch: 9 [47000/60000 (78%)]\tLoss: 0.058575\n",
      "Train Epoch: 9 [48000/60000 (80%)]\tLoss: 0.022797\n",
      "Train Epoch: 9 [49000/60000 (82%)]\tLoss: 0.204839\n",
      "Train Epoch: 9 [50000/60000 (83%)]\tLoss: 0.046070\n",
      "Train Epoch: 9 [51000/60000 (85%)]\tLoss: 0.006066\n",
      "Train Epoch: 9 [52000/60000 (87%)]\tLoss: 0.011137\n",
      "Train Epoch: 9 [53000/60000 (88%)]\tLoss: 0.004169\n",
      "Train Epoch: 9 [54000/60000 (90%)]\tLoss: 0.013364\n",
      "Train Epoch: 9 [55000/60000 (92%)]\tLoss: 0.014184\n",
      "Train Epoch: 9 [56000/60000 (93%)]\tLoss: 0.051962\n",
      "Train Epoch: 9 [57000/60000 (95%)]\tLoss: 0.025418\n",
      "Train Epoch: 9 [58000/60000 (97%)]\tLoss: 0.004272\n",
      "Train Epoch: 9 [59000/60000 (98%)]\tLoss: 0.001705\n",
      "\n",
      "Test set: Average loss: 0.0078, Accuracy: 9750/10000 (98%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Dataset references:\n",
    "http://pjreddie.com/media/files/mnist_train.csv\n",
    "http://pjreddie.com/media/files/mnist_test.csv\n",
    "\"\"\"\n",
    "\n",
    "from pathlib import Path\n",
    "from typing import Tuple\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "torch.manual_seed(1337)\n",
    "\n",
    "class MnistMlp(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, inputnodes: int, hiddennodes: int, outputnodes: int) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        # number of nodes (neurons) in input, hidden, and output layer\n",
    "        self.wih = torch.nn.Linear(in_features=inputnodes, out_features=hiddennodes)\n",
    "        self.who = torch.nn.Linear(in_features=hiddennodes, out_features=outputnodes)\n",
    "        self.activation = torch.nn.Sigmoid()\n",
    "\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        out = self.wih(x)\n",
    "        out = self.activation(out)\n",
    "        out = self.who(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class MnistDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, filepath: Path) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.data_list = None\n",
    "        with open(filepath, \"r\") as f:\n",
    "            self.data_list = f.readlines()\n",
    "\n",
    "        # conver string data to torch Tensor data type\n",
    "        self.features = []\n",
    "        self.targets = []\n",
    "        for record in self.data_list:\n",
    "            all_values = record.split(\",\")\n",
    "            features = np.asfarray(all_values[1:])\n",
    "            target = int(all_values[0])\n",
    "            self.features.append(features)\n",
    "            self.targets.append(target)\n",
    "\n",
    "        self.features = torch.tensor(np.array(self.features), dtype=torch.float) / 255.0\n",
    "        self.targets = torch.tensor(np.array(self.targets), dtype=torch.long)\n",
    "        # print(self.features.shape)\n",
    "        # print(self.targets.shape)\n",
    "        # print(self.features.max(), self.features.min())\n",
    "\n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        return len(self.features)\n",
    "    \n",
    "    def __getitem__(self, index) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        return self.features[index], self.targets[index]\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Device for training\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    # Initialize empty lists to store training and test losses during training\n",
    "    training_losses = []\n",
    "    test_losses = []\n",
    "\n",
    "    # NN architecture:\n",
    "    # number of input, hidden and output nodes\n",
    "    input_nodes = 784\n",
    "    hidden_nodes = 200\n",
    "    output_nodes = 10\n",
    "\n",
    "    # learning rate is 0.1\n",
    "    learning_rate = 0.1\n",
    "    # batch size\n",
    "    batch_size = 10\n",
    "    # number of epochs\n",
    "    epochs = 10\n",
    "\n",
    "    # Load mnist training and testing data CSV file into a datasets\n",
    "    train_dataset = MnistDataset(filepath=\"./mnist_train.csv\")\n",
    "    test_dataset = MnistDataset(filepath=\"./mnist_test.csv\")\n",
    "\n",
    "    # Make data loaders\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size)\n",
    "    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "    # Define NN\n",
    "    model = MnistMlp(inputnodes=input_nodes, \n",
    "                     hiddennodes=hidden_nodes, \n",
    "                     outputnodes=output_nodes)\n",
    "    # Number of parameters in the model\n",
    "    print(f\"# Params: {sum(p.numel() for p in model.parameters() if p.requires_grad)}\")\n",
    "    model = model.to(device=device)\n",
    "    \n",
    "    # Define Loss\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    # Define optimizer\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # Initialize variables for metrics\n",
    "    true_labels = []\n",
    "    predicted_labels = []\n",
    "\n",
    "    ##### Training! #####\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        test_loss = 0.0\n",
    "        correct = 0\n",
    "\n",
    "        for batch_idx, (features, target) in enumerate(train_loader):\n",
    "            features, target = features.to(device), target.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(features)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if batch_idx % 100 == 0:\n",
    "                print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                    epoch, batch_idx * len(features), len(train_loader.dataset),\n",
    "                    100. * batch_idx / len(train_loader), loss.item()))\n",
    "            \n",
    "            # Accumulate the running loss\n",
    "            running_loss += loss.item()\n",
    "    \n",
    "        # Calculate the average training loss for the epoch\n",
    "        average_train_loss = running_loss / len(train_loader)\n",
    "        training_losses.append(average_train_loss)\n",
    "        ##### Testing! #####\n",
    "        model.eval()\n",
    "        with torch.inference_mode():\n",
    "            for features, target in test_loader:\n",
    "                features, target = features.to(device), target.to(device)\n",
    "                output = model(features)\n",
    "                test_loss += criterion(output, target).item()  # sum up batch loss\n",
    "                pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "                correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "                # Collect true and predicted labels\n",
    "                true_labels.extend(target.cpu().numpy())\n",
    "                predicted_labels.extend(pred.cpu().numpy().flatten())\n",
    "\n",
    "        test_loss /= len(test_loader.dataset)\n",
    "        test_losses.append(test_loss)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "\n",
    "    # Convert lists to NumPy arrays\n",
    "    true_labels = np.array(true_labels)\n",
    "    predicted_labels = np.array(predicted_labels)\n",
    "\n",
    "    # Compute the confusion matrix\n",
    "    conf_matrix = confusion_matrix(true_labels, predicted_labels)\n",
    "\n",
    "    # Compute the classification report\n",
    "    class_report = classification_report(true_labels, predicted_labels, target_names=[str(i) for i in range(10)])\n",
    "\n",
    "    # Calculate accuracy per class and general accuracy\n",
    "    class_accuracy = conf_matrix.diagonal() / conf_matrix.sum(axis=1)\n",
    "    general_accuracy = np.sum(conf_matrix.diagonal()) / np.sum(conf_matrix)\n",
    "\n",
    "    # Save Model\n",
    "    torch.save(model.state_dict(), \"mnist_1.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix:\n",
      "[[ 9687     0    14    12     4    35    17    10    16     5]\n",
      " [    0 11232    19    13     0    13    20    10    42     1]\n",
      " [   82    51  9850    87    43     7    44    45   100    11]\n",
      " [    9    13    50  9764     8   110     2    45    51    48]\n",
      " [   12     5    22     7  9418     0    57    13    23   263]\n",
      " [   66    18     6   103    20  8531    47    16    68    45]\n",
      " [  106    32    21     1    64   170  9130     2    54     0]\n",
      " [    8   146   155    51    59    11     0  9545    12   293]\n",
      " [   44    46    30   116    55    75    50    34  9228    62]\n",
      " [   56    60     6    70   124    54     4    29    15  9672]]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nConfusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.imshow(conf_matrix, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(10)\n",
    "plt.xticks(tick_marks, [str(i) for i in range(10)], rotation=45)\n",
    "plt.yticks(tick_marks, [str(i) for i in range(10)])\n",
    "plt.tight_layout()\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print Classification Report with Precision, Recall and F1-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.98      9800\n",
      "           1       0.97      0.99      0.98     11350\n",
      "           2       0.97      0.95      0.96     10320\n",
      "           3       0.96      0.97      0.96     10100\n",
      "           4       0.96      0.96      0.96      9820\n",
      "           5       0.95      0.96      0.95      8920\n",
      "           6       0.97      0.95      0.96      9580\n",
      "           7       0.98      0.93      0.95     10280\n",
      "           8       0.96      0.95      0.95      9740\n",
      "           9       0.93      0.96      0.94     10090\n",
      "\n",
      "    accuracy                           0.96    100000\n",
      "   macro avg       0.96      0.96      0.96    100000\n",
      "weighted avg       0.96      0.96      0.96    100000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nClassification Report:\")\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print accuracy per class and general accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy Per Class:\n",
      "Class 0: 0.9885\n",
      "Class 1: 0.9896\n",
      "Class 2: 0.9545\n",
      "Class 3: 0.9667\n",
      "Class 4: 0.9591\n",
      "Class 5: 0.9564\n",
      "Class 6: 0.9530\n",
      "Class 7: 0.9285\n",
      "Class 8: 0.9474\n",
      "Class 9: 0.9586\n",
      "\n",
      "General Accuracy: 0.9606\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"\\nAccuracy Per Class:\")\n",
    "for i, acc in enumerate(class_accuracy):\n",
    "    print(f\"Class {i}: {acc:.4f}\")\n",
    "\n",
    "print(f\"\\nGeneral Accuracy: {general_accuracy:.4f}\")\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
