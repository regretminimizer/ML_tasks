{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMDB Reviews Sentiment Analysis with RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal is to train RNN model on IMDB Dataset of 50K Movie Reviews. This is a dataset for binary sentiment classification containing substantially more data than previous benchmark datasets. It consists of a set of 25,000 highly polar movie reviews for training and 25,000 for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-11 01:11:49.382141: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Probably my all-time favorite movie, a story o...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>I sure would like to see a resurrection of a u...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>This show was an amazing, fresh &amp; innovative i...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Encouraged by the positive comments about this...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>If you like original gut wrenching laughter yo...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
       "5  Probably my all-time favorite movie, a story o...  positive\n",
       "6  I sure would like to see a resurrection of a u...  positive\n",
       "7  This show was an amazing, fresh & innovative i...  negative\n",
       "8  Encouraged by the positive comments about this...  negative\n",
       "9  If you like original gut wrenching laughter yo...  positive"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import io\n",
    "from tqdm import tqdm\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer \n",
    "import os, re, csv, math, codecs\n",
    "from sklearn import model_selection\n",
    "from sklearn import metrics\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.multiprocessing as mp\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import tensorflow as tf  # we use both tensorflow and pytorch (pytorch for main part) , tensorflow for tokenizer\n",
    "\n",
    "torch.manual_seed(1337)\n",
    "\n",
    "try:\n",
    "    mp.set_start_method('spawn')\n",
    "except RuntimeError:\n",
    "    pass\n",
    "\n",
    "df = pd.read_csv('./IMDB Dataset.csv', \n",
    "                 encoding='utf-8')\n",
    "\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since there HTML marks and other peculiarities in the text. Let's clean them using Beautiful Soup and RegEx."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. The filming tec...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Probably my all-time favorite movie, a story o...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>I sure would like to see a resurrection of a u...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>This show was an amazing, fresh &amp; innovative i...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Encouraged by the positive comments about this...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>If you like original gut wrenching laughter yo...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. The filming tec...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
       "5  Probably my all-time favorite movie, a story o...  positive\n",
       "6  I sure would like to see a resurrection of a u...  positive\n",
       "7  This show was an amazing, fresh & innovative i...  negative\n",
       "8  Encouraged by the positive comments about this...  negative\n",
       "9  If you like original gut wrenching laughter yo...  positive"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#Getting rid of  html strips\n",
    "def strip_html(text):\n",
    "    soup = BeautifulSoup(text, \"html.parser\")\n",
    "    return soup.get_text()\n",
    "\n",
    "#Removing the square brackets\n",
    "def remove_between_square_brackets(text):\n",
    "    return re.sub('\\[[^]]*\\]', '', text)\n",
    "\n",
    "#Removing the noisy text\n",
    "def denoise_text(text):\n",
    "    text = strip_html(text)\n",
    "    text = remove_between_square_brackets(text)\n",
    "    return text\n",
    "#Apply function on review column\n",
    "df['review']=df['review'].apply(denoise_text)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's convert sentiment column to a binari label and add a 5-fold cross-validation group column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>kfold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I watched this movie only because I didn't wan...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What an embarassment...This doesnt do justice ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I can not believe the positive reaction to thi...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Like many western Pennsylvania history buffs, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SLASHERS (2 outta 5 stars)Not really a very go...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>i think dirty dancing was a great movie, they ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>My Super Ex Girlfriend turned out to be a plea...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Billy Chung Siu Hung's (the bloody swordplay f...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>What was always missing with the Matrix story ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>What a truly moronic movie, all I can say is t...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment  kfold\n",
       "0  I watched this movie only because I didn't wan...          1      0\n",
       "1  What an embarassment...This doesnt do justice ...          0      0\n",
       "2  I can not believe the positive reaction to thi...          0      0\n",
       "3  Like many western Pennsylvania history buffs, ...          0      0\n",
       "4  SLASHERS (2 outta 5 stars)Not really a very go...          0      0\n",
       "5  i think dirty dancing was a great movie, they ...          1      0\n",
       "6  My Super Ex Girlfriend turned out to be a plea...          1      0\n",
       "7  Billy Chung Siu Hung's (the bloody swordplay f...          0      0\n",
       "8  What was always missing with the Matrix story ...          1      0\n",
       "9  What a truly moronic movie, all I can say is t...          0      0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sentiment = df.sentiment.apply(lambda x: 1 if x=='positive' else 0)\n",
    "\n",
    "df['kfold'] = -1\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "y = df.sentiment.values\n",
    "\n",
    "kf = model_selection.StratifiedKFold(n_splits=5)\n",
    "for fold, (train_, valid_) in enumerate(kf.split(X=df, y=y)):\n",
    "    df.loc[valid_, 'kfold'] = fold\n",
    "    \n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, I use Facebook (2016) FastText. It's loaded from: https://fasttext.cc/docs/en/english-vectors.html\n",
    "It's better than Word2Vec since it accounts word parts into and  enables training of embeddings on smaller datasets and generalization to unknown words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "999995it [01:20, 12443.47it/s]\n"
     ]
    }
   ],
   "source": [
    "fasttext_embedding = {}\n",
    "f = codecs.open('./wiki-news-300d-1M.vec', encoding='utf-8')\n",
    "for line in tqdm(f):\n",
    "    values = line.rstrip().rsplit(' ')\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    fasttext_embedding[word] = coefs\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, I use Standford (2014) GloVe 6B tokens, 400K vocab, uncased, 300d vectors. It is an unsupervised learning algorithm for obtaining vector representations for words. Training is performed on aggregated global word-word co-occurrence statistics from a corpus, and the resulting representations showcase interesting linear substructures of the word vector space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove = pd.read_csv('./glove/glove.6B.300d.txt', sep=\" \", quoting=3, header=None, index_col=0)\n",
    "glove_embedding = {key: val.values for key, val in glove.T.items()}\n",
    "\n",
    "glove_embedding['hello'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, I create IMDBdataset class that takes embedding matrix and returns torch tensor output datatype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IMDBDataset:\n",
    "    def __init__(self, reviews, targets):\n",
    "        self.reviews = reviews\n",
    "        self.target = targets\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.reviews)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        review = torch.tensor(self.reviews[index,:], dtype = torch.long)\n",
    "        target = torch.tensor(self.target[index], dtype = torch.float)\n",
    "        \n",
    "        return {'review': review,\n",
    "                'target': target}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's build a bidirectional LSTM model class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, embedding_matrix):\n",
    "        super(LSTM, self).__init__()\n",
    "        \n",
    "        num_words = embedding_matrix.shape[0]           # Number of words - num of rows\n",
    "        embedding_dim = embedding_matrix.shape[1]       # Embedding Dimension - num of columns\n",
    "        self.embedding = nn.Embedding(\n",
    "                                      num_embeddings=num_words,\n",
    "                                      embedding_dim=embedding_dim)\n",
    "        \n",
    "        self.embedding.weight = nn.Parameter(torch.tensor(embedding_matrix, dtype = torch.float32))\n",
    "        self.embedding.weight.requires_grad = False     # not training gradient on embedding weight since I use pretrained embedding\n",
    "        \n",
    "        self.lstm = nn.LSTM(\n",
    "                            embedding_dim, \n",
    "                            128,\n",
    "                            bidirectional=True,\n",
    "                            batch_first=True,\n",
    "                             )                          # hidden_size is 128\n",
    "        self.out = nn.Linear(512, 1)                    # hidden_size*2 + maxpooling **2  = 128*4  (bi-directional LSTM)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        hidden, _ = self.lstm(x)\n",
    "        avg_pool= torch.mean(hidden, 1)\n",
    "        max_pool, index_max_pool = torch.max(hidden, 1)     # mean and max pooling on lstm output\n",
    "        out = torch.cat((avg_pool, max_pool), 1)            # bidirectional: 256*2 \n",
    "        out = self.out(out)                                 # dim reduction 512 to 1\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If there is a GPU available, let's use it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU not available, CPU used\n"
     ]
    }
   ],
   "source": [
    "is_cuda = torch.cuda.is_available()\n",
    "\n",
    "if is_cuda:\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"GPU is available\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"GPU not available, CPU used\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, I construct the model training function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(data_loader, model, optimizer, device):\n",
    "    model.train()\n",
    "    for data in data_loader:\n",
    "        reviews = data['review']\n",
    "        targets = data['target']\n",
    "        \n",
    "        reviews = reviews.to(device, dtype = torch.long)\n",
    "        targets = targets.to(device, dtype = torch.float)\n",
    "    \n",
    "        optimizer.zero_grad()\n",
    "        predictions = model(reviews)\n",
    "        \n",
    "        loss = nn.BCEWithLogitsLoss()(predictions, targets.view(-1,1))\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, the model evaluation function is constructed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(data_loader, model, device):\n",
    "    \n",
    "    final_predictions = []\n",
    "    final_targets = []\n",
    "    model.eval()\n",
    "   \n",
    "    with torch.no_grad():\n",
    "        for data in data_loader:\n",
    "            reviews = data['review']\n",
    "            targets = data['target']\n",
    "            reviews = reviews.to(device, dtype = torch.long)\n",
    "            targets = targets.to(device, dtype=torch.float)\n",
    "            \n",
    "            predictions = model(reviews)\n",
    "            \n",
    "            predictions = predictions.cpu().numpy().tolist()\n",
    "            targets = data['target'].cpu().numpy().tolist()\n",
    "            \n",
    "            final_predictions.extend(predictions)\n",
    "            final_targets.extend(targets)\n",
    "    return final_predictions, final_targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Paramaters' configuration and saving embedding matrix into a numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 128\n",
    "TRAIN_BATCH_SIZE = 64\n",
    "VALID_BATCH_SIZE = 32\n",
    "EPOCHS = 8\n",
    "\n",
    "def create_embedding_matrix(word_index, embedding_dict=None, d_model=300):\n",
    "    \n",
    "    embedding_matrix = np.zeros((len(word_index) + 1, d_model))\n",
    "    \n",
    "    for word, index in word_index.items():\n",
    "        if word in embedding_dict:\n",
    "            embedding_matrix[index] = embedding_dict[word]\n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, I tokenize with Keras Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tf.keras.preprocessing.text.Tokenizer()\n",
    "tokenizer.fit_on_texts(df.review.values.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's train the model with FastText embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training model\n",
      "FOLD:0, epoch: 0, accuracy: 0.8315\n",
      "FOLD:0, epoch: 1, accuracy: 0.8678\n",
      "FOLD:0, epoch: 2, accuracy: 0.8658\n",
      "FOLD:0, epoch: 3, accuracy: 0.8718\n",
      "FOLD:0, epoch: 4, accuracy: 0.876\n",
      "FOLD:0, epoch: 5, accuracy: 0.8743\n",
      "FOLD:0, epoch: 6, accuracy: 0.8737\n",
      "FOLD:0, epoch: 7, accuracy: 0.874\n",
      "training model\n",
      "FOLD:1, epoch: 0, accuracy: 0.837\n",
      "FOLD:1, epoch: 1, accuracy: 0.8608\n",
      "FOLD:1, epoch: 2, accuracy: 0.8559\n",
      "FOLD:1, epoch: 3, accuracy: 0.8599\n",
      "FOLD:1, epoch: 4, accuracy: 0.8675\n",
      "FOLD:1, epoch: 5, accuracy: 0.8676\n",
      "FOLD:1, epoch: 6, accuracy: 0.8671\n",
      "FOLD:1, epoch: 7, accuracy: 0.8685\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    \n",
    "    embedding_matrix = create_embedding_matrix(tokenizer.word_index, embedding_dict=fasttext_embedding, d_model=300)\n",
    "\n",
    "    for fold in range(2):\n",
    "   \n",
    "        train_df = df[df.kfold != fold].reset_index(drop=True)\n",
    "        valid_df = df[df.kfold == fold].reset_index(drop=True)\n",
    "    \n",
    "        xtrain = tokenizer.texts_to_sequences(train_df.review.values)\n",
    "        xtest = tokenizer.texts_to_sequences(valid_df.review.values)\n",
    "    \n",
    "        xtrain = tf.keras.preprocessing.sequence.pad_sequences(xtrain, maxlen=MAX_LEN)     \n",
    "        xtest = tf.keras.preprocessing.sequence.pad_sequences(xtest, maxlen=MAX_LEN)\n",
    "    \n",
    "        train_dataset = IMDBDataset(reviews=xtrain, targets=train_df.sentiment.values)\n",
    "        train_data_loader = torch.utils.data.DataLoader(train_dataset, batch_size = TRAIN_BATCH_SIZE, num_workers=0)\n",
    "    \n",
    "        valid_dataset = IMDBDataset(reviews=xtest, targets=valid_df.sentiment.values)\n",
    "        valid_data_loader = torch.utils.data.DataLoader(valid_dataset, batch_size = VALID_BATCH_SIZE, num_workers=0)\n",
    "    \n",
    "        model_fasttext = LSTM(embedding_matrix)\n",
    "        model_fasttext.to(device)\n",
    "    \n",
    "        optimizer = torch.optim.Adam(model_fasttext.parameters(), lr=1e-3)\n",
    "        scheduler = StepLR(optimizer, step_size=1, gamma=0.5)\n",
    "        print('training model')\n",
    "   \n",
    "        for epoch in range(EPOCHS):\n",
    "            train(train_data_loader, model_fasttext, optimizer, device)\n",
    "            outputs, targets = evaluate(valid_data_loader, model_fasttext, device)\n",
    "            outputs = np.array(outputs) >= 0.5\n",
    "            scheduler.step()\n",
    "            accuracy = metrics.accuracy_score(targets, outputs)\n",
    "            print(f'FOLD:{fold}, epoch: {epoch}, accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, I train the GloVe embedding model with the kernel size 300."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training model\n",
      "FOLD:0, epoch: 0, accuracy: 0.8555\n",
      "FOLD:0, epoch: 1, accuracy: 0.874\n",
      "FOLD:0, epoch: 2, accuracy: 0.8755\n",
      "FOLD:0, epoch: 3, accuracy: 0.8784\n",
      "FOLD:0, epoch: 4, accuracy: 0.8841\n",
      "FOLD:0, epoch: 5, accuracy: 0.884\n",
      "FOLD:0, epoch: 6, accuracy: 0.8844\n",
      "FOLD:0, epoch: 7, accuracy: 0.8839\n",
      "training model\n",
      "FOLD:1, epoch: 0, accuracy: 0.8517\n",
      "FOLD:1, epoch: 1, accuracy: 0.8721\n",
      "FOLD:1, epoch: 2, accuracy: 0.8731\n",
      "FOLD:1, epoch: 3, accuracy: 0.8729\n",
      "FOLD:1, epoch: 4, accuracy: 0.8816\n",
      "FOLD:1, epoch: 5, accuracy: 0.8802\n",
      "FOLD:1, epoch: 6, accuracy: 0.8802\n",
      "FOLD:1, epoch: 7, accuracy: 0.8803\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    \n",
    "    embedding_matrix = create_embedding_matrix(tokenizer.word_index, embedding_dict=glove_embedding, d_model=300)\n",
    "\n",
    "    for fold in range(2):\n",
    "    \n",
    "        train_df = df[df.kfold != fold].reset_index(drop=True)\n",
    "        valid_df = df[df.kfold == fold].reset_index(drop=True)\n",
    "    \n",
    "        xtrain = tokenizer.texts_to_sequences(train_df.review.values)\n",
    "        xtest = tokenizer.texts_to_sequences(valid_df.review.values)\n",
    "    \n",
    "        xtrain = tf.keras.preprocessing.sequence.pad_sequences(xtrain, maxlen=MAX_LEN)\n",
    "        xtest = tf.keras.preprocessing.sequence.pad_sequences(xtest, maxlen=MAX_LEN)\n",
    "    \n",
    "        train_dataset = IMDBDataset(reviews=xtrain, targets=train_df.sentiment.values)\n",
    "    \n",
    "        train_data_loader = torch.utils.data.DataLoader(train_dataset, batch_size = TRAIN_BATCH_SIZE, num_workers=0)\n",
    "        valid_dataset = IMDBDataset(reviews=xtest, targets=valid_df.sentiment.values)\n",
    "        valid_data_loader = torch.utils.data.DataLoader(valid_dataset, batch_size = VALID_BATCH_SIZE, num_workers=0)\n",
    "    \n",
    "        model_glove = LSTM(embedding_matrix)\n",
    "        model_glove.to(device)\n",
    "    \n",
    "        optimizer = torch.optim.Adam(model_glove.parameters(), lr=1e-3)\n",
    "        scheduler = StepLR(optimizer, step_size=1, gamma=0.5)\n",
    "        print('training model')\n",
    "   \n",
    "        for epoch in range(EPOCHS):\n",
    "        \n",
    "            train(train_data_loader, model_glove, optimizer, device)\n",
    "            outputs, targets = evaluate(valid_data_loader, model_glove, device)\n",
    "            outputs = np.array(outputs) >= 0.5\n",
    "            scheduler.step()\n",
    "            accuracy = metrics.accuracy_score(targets, outputs)\n",
    "            print(f'FOLD:{fold}, epoch: {epoch}, accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try checking the best FastText model classification by feeding it with the sampl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------> Positive\n",
      "------> Positive\n",
      "------> Positive\n",
      "------> Positive\n",
      "------> Positive\n",
      "------> Positive\n",
      "------> Positive\n",
      "------> Positive\n"
     ]
    }
   ],
   "source": [
    "def Interact_user_input(model):\n",
    "\n",
    "    model.eval()\n",
    "    \n",
    "    sentence = 'If you like original gut wrenching laughter'\n",
    "    while True:\n",
    "        try:\n",
    "            sentence = input('Review: ')\n",
    "            if sentence in ['q','quit']: \n",
    "                break\n",
    "            sentence = np.array([sentence])\n",
    "            sentence_token = tokenizer.texts_to_sequences(sentence)\n",
    "            sentence_token = tf.keras.preprocessing.sequence.pad_sequences(sentence_token, maxlen = MAX_LEN)\n",
    "            sentence_train = torch.tensor(sentence_token, dtype = torch.long).to(device, dtype = torch.long)\n",
    "            predict = model(sentence_train)\n",
    "            if predict.item() > 0.5:\n",
    "                print('------> Positive')\n",
    "            else:\n",
    "                print('------> Negative')\n",
    "        except KeyError:\n",
    "            print('please enter again')\n",
    "    \n",
    "Interact_user_input(model_glove)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
