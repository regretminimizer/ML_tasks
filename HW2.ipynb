{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-1-db2af9f1058c>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-db2af9f1058c>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    def rmse_regression(guess: np.array, x: np.array, y: np.array) -> float:\u001b[0m\n\u001b[0m                             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# 2) Calculate RMSE and MAE\n",
    "def rmse_regression(guess: np.array, x: np.array, y: np.array) -> float:\n",
    "    \"\"\"RMSE Minimization Regression\"\"\"\n",
    "    m = guess[0]\n",
    "    b = guess[1]\n",
    "    # Predictions\n",
    "    y_hat = m * x + b\n",
    "    # Get loss MSE\n",
    "    rmse = np.sqrt(np.mean((y - y_pred) ** 2))\n",
    "    return rmse\n",
    "\n",
    "print(results(rmse_regression,\n",
    "        initial_guess,\n",
    "        args=(x, y,),\n",
    "        method=\"Nelder-Mead\",\n",
    "        options={\"disp\": True}))\n",
    "\n",
    "def mae_regression(guess: np.array, x: np.array, y: np.array) -> float:\n",
    "    \"\"\"MAE Minimization Regression\"\"\"\n",
    "    m = guess[0]\n",
    "    b = guess[1]\n",
    "    # Predictions\n",
    "    y_hat = m * x + b\n",
    "    # Get loss MSE\n",
    "    mae = np.mean(np.abs(y - y_pred))\n",
    "    return mae\n",
    "\n",
    "print(results(mae_regression))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "np.random.seed(1337)\n",
    "\n",
    "def get_data(nsamples: int = 100) -> Tuple[np.array, np.array]:\n",
    "    x = np.linspace(0, 10, nsamples)\n",
    "    y = 2 * x + 3.5\n",
    "    return x, y\n",
    "\n",
    "\n",
    "def add_noise(y: np.array) -> np.array:\n",
    "    noise = np.random.normal(size=y.size)\n",
    "    return y + noise\n",
    "\n",
    "\n",
    "def mse_regression(guess: np.array, x: np.array, y: np.array) -> float:\n",
    "    \"\"\"MSE Minimization Regression\"\"\"\n",
    "    m = guess[0]\n",
    "    b = guess[1]\n",
    "    # Predictions\n",
    "    y_hat = m * x + b\n",
    "    # Get loss MSE\n",
    "    mse = (np.square(y - y_hat)).mean()\n",
    "    return mse\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Getting data\n",
    "    x, y_true = get_data()\n",
    "    y = add_noise(y_true)\n",
    "\n",
    "    # Plot and investigate data\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    ax.plot(x, y, \"o\", label=\"data\")\n",
    "    ax.legend(loc=\"best\")\n",
    "    plt.savefig(\"data.png\")\n",
    "\n",
    "    # Initial guess of the parameters: [2, 2] (m, b).\n",
    "    # It doesn’t have to be accurate but simply reasonable.\n",
    "    initial_guess = np.array([5, -3])\n",
    "\n",
    "    # Maximizing the probability for point to be from the distribution\n",
    "    results = minimize(\n",
    "        mse_regression,\n",
    "        initial_guess,\n",
    "        args=(x, y,),\n",
    "        method=\"Nelder-Mead\",\n",
    "        options={\"disp\": True})\n",
    "    print(results)\n",
    "    print(\"Parameters: \", results.x)\n",
    "\n",
    "    # Plot results\n",
    "    xx = np.linspace(np.min(x), np.max(x), 100)\n",
    "    yy = results.x[0] * xx + results.x[1]\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    ax.plot(x, y, \"o\", label=\"data\")\n",
    "    ax.plot(x, y_true, \"b-\", label=\"True\")\n",
    "    ax.plot(xx, yy, \"r--.\", label=\"MLE\")\n",
    "    ax.legend(loc=\"best\")\n",
    "\n",
    "    # Store loss function values at each iteration\n",
    "    loss_history = []\n",
    "    loss_history_rmse = []\n",
    "    loss_history_mae = []\n",
    "\n",
    "    # Optimization process with recording loss values\n",
    "    def record_loss(guess):\n",
    "        loss = mse_regression(guess, x, y)\n",
    "        loss_rmse = np.sqrt(mse_regression(guess, x, y))\n",
    "        loss_mae = np.mean(np.abs(guess[0] * x + guess[1] - y))\n",
    "        loss_history.append(loss)\n",
    "        loss_history_rmse.append(loss_rmse)\n",
    "        loss_history_mae.append(loss_mae)\n",
    "\n",
    "    minimize(mse_regression, initial_guess, args=(x, y), method=\"Nelder-Mead\", callback=record_loss)\n",
    "\n",
    "    # Plot loss function value on iteration number for MSE\n",
    "    plt.figure()\n",
    "    plt.plot(range(len(loss_history)), loss_history, marker='o')\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel('MSE Loss')\n",
    "    plt.title('Loss Function on Iteration Number')\n",
    "    \n",
    "    # Plot loss function value on iteration number for RMSE\n",
    "    plt.figure()\n",
    "    plt.plot(range(len(loss_history_rmse)), loss_history_rmse, marker='o')\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel('RMSE Loss')\n",
    "    plt.title('RMSE Loss on Iteration Number')\n",
    "\n",
    "    # Plot loss function value on iteration number for MAE\n",
    "    plt.figure()\n",
    "    plt.plot(range(len(loss_history_mae)), loss_history_mae, marker='o')\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel('MAE Loss')\n",
    "    plt.title('MAE Loss on Iteration Number')\n",
    "\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "np.random.seed(1337)\n",
    "\n",
    "def get_data_linear(nsamples: int = 100) -> Tuple[np.array, np.array]:\n",
    "    x = np.linspace(0, 10, nsamples)\n",
    "    y = 2 * x + 3.5\n",
    "    return x, y\n",
    "\n",
    "def get_data_quadratic(nsamples: int = 100) -> Tuple[np.array, np.array]:\n",
    "    x = np.linspace(0, 10, nsamples)\n",
    "    y = 2 * x**2 + x + 3.5\n",
    "    return x, y\n",
    "\n",
    "def add_noise(y: np.array) -> np.array:\n",
    "    noise = np.random.normal(size=y.size)\n",
    "    return y + noise\n",
    "\n",
    "def mse_regression(guess: np.array, x: np.array, y: np.array) -> float:\n",
    "    \"\"\"MSE Minimization Regression\"\"\"\n",
    "    m = guess[0]\n",
    "    b = guess[1]\n",
    "    # Predictions\n",
    "    y_hat = m * x + b\n",
    "    # Get loss MSE\n",
    "    mse = (np.square(y - y_hat)).mean()\n",
    "    return mse\n",
    "\n",
    "def rmse_regression(guess: np.array, x: np.array, y: np.array) -> float:\n",
    "    \"\"\"RMSE Minimization Regression\"\"\"\n",
    "    mse = mse_regression(guess, x, y)\n",
    "    rmse = np.sqrt(mse)\n",
    "    return rmse\n",
    "\n",
    "def mae_regression(guess: np.array, x: np.array, y: np.array) -> float:\n",
    "    \"\"\"MAE Minimization Regression\"\"\"\n",
    "    m = guess[0]\n",
    "    b = guess[1]\n",
    "    y_hat = m * x + b\n",
    "    mae = np.mean(np.abs(y - y_hat))\n",
    "    return mae\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Getting linear data\n",
    "    x_linear, y_true_linear = get_data_linear()\n",
    "    y_linear = add_noise(y_true_linear)\n",
    "\n",
    "    # Getting quadratic data\n",
    "    x_quadratic, y_true_quadratic = get_data_quadratic()\n",
    "    y_quadratic = add_noise(y_true_quadratic)\n",
    "\n",
    "    # Plot and investigate linear data\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    ax.plot(x_linear, y_linear, \"o\", label=\"data (linear)\")\n",
    "    ax.legend(loc=\"best\")\n",
    "\n",
    "    # Initial guess of the parameters: [2, 2] (m, b).\n",
    "    # It doesn’t have to be accurate but simply reasonable.\n",
    "    initial_guess_linear = np.array([5, -3])\n",
    "\n",
    "    # Maximizing the probability for point to be from the distribution for linear data\n",
    "    results_linear = minimize(\n",
    "        mse_regression,\n",
    "        initial_guess_linear,\n",
    "        args=(x_linear, y_linear,),\n",
    "        method=\"Nelder-Mead\",\n",
    "        options={\"disp\": True}\n",
    "    )\n",
    "    print(\"Linear Regression Results:\")\n",
    "    print(results_linear)\n",
    "    print(\"Parameters (Linear): \", results_linear.x)\n",
    "\n",
    "    # Plot linear results\n",
    "    xx_linear = np.linspace(np.min(x_linear), np.max(x_linear), 100)\n",
    "    yy_linear = results_linear.x[0] * xx_linear + results_linear.x[1]\n",
    "\n",
    "    ax.plot(x_linear, y_true_linear, \"b-\", label=\"True (linear)\")\n",
    "    ax.plot(xx_linear, yy_linear, \"r--.\", label=\"MLE (linear)\")\n",
    "\n",
    "    # Plot and investigate quadratic data\n",
    "    ax.plot(x_quadratic, y_quadratic, \"o\", label=\"data (quadratic)\")\n",
    "\n",
    "    # Initial guess of the parameters: [2, 2] (m, b).\n",
    "    initial_guess_quadratic = np.array([1, 1, 1])\n",
    "\n",
    "    # Maximizing the probability for point to be from the distribution for quadratic data\n",
    "    results_quadratic = minimize(\n",
    "        mse_regression,\n",
    "        initial_guess_quadratic,\n",
    "        args=(x_quadratic, y_quadratic,),\n",
    "        method=\"Nelder-Mead\",\n",
    "        options={\"disp\": True}\n",
    "    )\n",
    "    print(\"Quadratic Regression Results:\")\n",
    "    print(results_quadratic)\n",
    "    print(\"Parameters (Quadratic): \", results_quadratic.x)\n",
    "\n",
    "    # Plot quadratic results\n",
    "    xx_quadratic = np.linspace(np.min(x_quadratic), np.max(x_quadratic), 100)\n",
    "    yy_quadratic = results_quadratic.x[0] * xx_quadratic**2 + results_quadratic.x[1] * xx_quadratic + results_quadratic.x[2]\n",
    "\n",
    "    ax.plot(x_quadratic, y_true_quadratic, \"g-\", label=\"True (quadratic)\")\n",
    "    ax.plot(xx_quadratic, yy_quadratic, \"m--.\", label=\"MLE (quadratic)\")\n",
    "\n",
    "    ax.legend()\n",
    "    plt.savefig(\"regression.png\")\n",
    "\n",
    "    # Store loss function values at each iteration for linear data\n",
    "    loss_history_linear = []\n",
    "    rmse_history_linear = []\n",
    "    mae_history_linear = []\n",
    "\n",
    "    # Optimization process with recording loss values for linear data\n",
    "    def record_loss_linear(guess):\n",
    "        loss = mse_regression(guess, x_linear, y_linear)\n",
    "        rmse = rmse_regression(guess, x_linear, y_linear)\n",
    "        mae = mae_regression(guess, x_linear, y_linear)\n",
    "        loss_history_linear.append(loss)\n",
    "        rmse_history_linear.append(rmse)\n",
    "        mae_history_linear.append(mae)\n",
    "\n",
    "    minimize(mse_regression, initial_guess_linear, args=(x_linear, y_linear), method=\"Nelder-Mead\", callback=record_loss_linear)\n",
    "\n",
    "    # Plot loss function value on iteration number for MSE (linear)\n",
    "    plt.figure()\n",
    "    plt.plot(range(len(loss_history_linear)), loss_history_linear, marker='o')\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel('MSE Loss (linear)')\n",
    "    plt.title('Loss Function on Iteration Number (linear)')\n",
    "\n",
    "    # Plot loss function value on iteration number for RMSE (linear)\n",
    "    plt.figure()\n",
    "    plt.plot(range(len(rmse_history_linear)), rmse_history_linear, marker='o')\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel('RMSE Loss (linear)')\n",
    "    plt.title('RMSE Loss on Iteration Number (linear)')\n",
    "\n",
    "    # Plot loss function value on iteration number for MAE (linear)\n",
    "    plt.figure()\n",
    "    plt.plot(range(len(mae_history_linear)), mae_history_linear, marker='o')\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel('MAE Loss (linear)')\n",
    "    plt.title('MAE Loss on Iteration Number (linear)')\n",
    "\n",
    "    # Store loss function values at each iteration for quadratic data\n",
    "    loss_history_quadratic = []\n",
    "    rmse_history_quadratic = []\n",
    "    mae_history_quadratic = []\n",
    "\n",
    "    # Optimization process with recording loss values for quadratic data\n",
    "    def record_loss_quadratic(guess):\n",
    "        loss = mse_regression(guess, x_quadratic, y_quadratic)\n",
    "        rmse = rmse_regression(guess, x_quadratic, y_quadratic)\n",
    "        mae = mae_regression(guess, x_quadratic, y_quadratic)\n",
    "        loss_history_quadratic.append(loss)\n",
    "        rmse_history_quadratic.append(rmse)\n",
    "        mae_history_quadratic.append(mae)\n",
    "\n",
    "    minimize(mse_regression, initial_guess_quadratic, args=(x_quadratic, y_quadratic), method=\"Nelder-Mead\", callback=record_loss_quadratic)\n",
    "\n",
    "    # Plot loss function value on iteration number for MSE (quadratic)\n",
    "    plt.figure()\n",
    "    plt.plot(range(len(loss_history_quadratic)), loss_history_quadratic, marker='o')\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel('MSE Loss (quadratic)')\n",
    "    plt.title('Loss Function on Iteration Number (quadratic)')\n",
    "\n",
    "    # Plot loss function value on iteration number for RMSE (quadratic)\n",
    "    plt.figure()\n",
    "    plt.plot(range(len(rmse_history_quadratic)), rmse_history_quadratic, marker='o')\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel('RMSE Loss (quadratic)')\n",
    "    plt.title('RMSE Loss on Iteration Number (quadratic)')\n",
    "\n",
    "    # Plot loss function value on iteration number for MAE (quadratic)\n",
    "    plt.figure()\n",
    "    plt.plot(range(len(mae_history_quadratic)), mae_history_quadratic, marker='o')\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel('MAE Loss (quadratic)')\n",
    "    plt.title('MAE Loss on Iteration Number (quadratic)')\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "np.random.seed(1337)\n",
    "\n",
    "def get_data_linear(nsamples: int = 100) -> Tuple[np.array, np.array]:\n",
    "    x = np.linspace(0, 10, nsamples)\n",
    "    y = 2 * x + 3.5\n",
    "    return x, y\n",
    "\n",
    "def get_data_quadratic(nsamples: int = 100) -> Tuple[np.array, np.array]:\n",
    "    x = np.linspace(0, 10, nsamples)\n",
    "    y = 2 * x**2 + x + 3.5\n",
    "    return x, y\n",
    "\n",
    "def add_noise(y: np.array) -> np.array:\n",
    "    noise = np.random.normal(size=y.size)\n",
    "    return y + noise\n",
    "\n",
    "def mse_regression(guess: np.array, x: np.array, y: np.array) -> float:\n",
    "    \"\"\"MSE Minimization Regression for Linear Case\"\"\"\n",
    "    m = guess[0]\n",
    "    b = guess[1]\n",
    "    # Predictions\n",
    "    y_hat = m * x + b\n",
    "    # Get loss MSE\n",
    "    mse = (np.square(y - y_hat)).mean()\n",
    "    return mse\n",
    "\n",
    "def rmse_regression(guess: np.array, x: np.array, y: np.array) -> float:\n",
    "    \"\"\"RMSE Minimization Regression\"\"\"\n",
    "    mse = mse_regression(guess, x, y)\n",
    "    rmse = np.sqrt(mse)\n",
    "    return rmse\n",
    "\n",
    "def mae_regression(guess: np.array, x: np.array, y: np.array) -> float:\n",
    "    \"\"\"MAE Minimization Regression\"\"\"\n",
    "    m = guess[0]\n",
    "    b = guess[1]\n",
    "    # Predictions\n",
    "    y_hat = m * x + b\n",
    "    mae = np.mean(np.abs(y - y_hat))\n",
    "    return mae\n",
    "\n",
    "\n",
    "def mse_regression_quadratic(guess_quadratic: np.array, x: np.array, y: np.array) -> float:\n",
    "    \"\"\"MSE Minimization Regression for Quadratic Case\"\"\"\n",
    "    a = guess_quadratic[0]\n",
    "    b = guess_quadratic[1]\n",
    "    c = guess_quadratic[2]\n",
    "    # Predictions\n",
    "    y_hat = a * x**2 + b * x + c\n",
    "    # Get loss MSE\n",
    "    mse = (np.square(y - y_hat)).mean()\n",
    "    return mse\n",
    "\n",
    "def rmse_regression_quadratic(guess_quadratic: np.array, x: np.array, y: np.array) -> float:\n",
    "    \"\"\"RMSE Minimization Regression\"\"\"\n",
    "    mse = mse_regression_quadratic(guess_quadratic, x, y)\n",
    "    rmse_quadratic = np.sqrt(mse)\n",
    "    return rmse_quadratic\n",
    "\n",
    "def mae_regression_quadratic(guess_quadratic: np.array, x: np.array, y: np.array) -> float:\n",
    "    \"\"\"MAE Minimization Regression\"\"\"\n",
    "    a = guess_quadratic[0]\n",
    "    b = guess_quadratic[1]\n",
    "    c = guess_quadratic[2]\n",
    "    y_hat = a * x**2 + b * x + c\n",
    "    mae_quadratic = np.mean(np.abs(y - y_hat))\n",
    "    return mae_quadratic\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Experiment with number of samples, initial guesses, and optimization methods\n",
    "    nsamples = 100\n",
    "    initial_guess_linear = np.array([5, -3])\n",
    "    initial_guess_quadratic = np.array([1, 1, 3])\n",
    "    method_linear = \"Nelder-Mead\"   \n",
    "    method_quadratic = \"Nelder-Mead\"\n",
    "\n",
    "    # Getting linear data\n",
    "    x_linear, y_true_linear = get_data_linear(nsamples)\n",
    "    y_linear = add_noise(y_true_linear)\n",
    "\n",
    "    # Getting quadratic data\n",
    "    x_quadratic, y_true_quadratic = get_data_quadratic(nsamples)\n",
    "    y_quadratic = add_noise(y_true_quadratic)\n",
    "\n",
    "    # Plot and investigate linear data\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    ax.plot(x_linear, y_linear, \"o\", label=\"data (linear)\")\n",
    "    ax.legend(loc=\"best\")\n",
    "\n",
    "    # Maximizing the probability for point to be from the distribution for linear data\n",
    "    results_linear = minimize(\n",
    "        mse_regression,\n",
    "        initial_guess_linear,\n",
    "        args=(x_linear, y_linear,),\n",
    "        method=method_linear,\n",
    "        options={\"disp\": True}\n",
    "    )\n",
    "    print(\"Linear Regression Results:\")\n",
    "    print(results_linear)\n",
    "    print(\"Parameters (Linear): \", results_linear.x)\n",
    "\n",
    "    # Plot linear results\n",
    "    xx_linear = np.linspace(np.min(x_linear), np.max(x_linear), 100)\n",
    "    yy_linear = results_linear.x[0] * xx_linear + results_linear.x[1]\n",
    "\n",
    "    ax.plot(x_linear, y_true_linear, \"b-\", label=\"True (linear)\")\n",
    "    ax.plot(xx_linear, yy_linear, \"r--.\", label=\"MLE (linear)\")\n",
    "\n",
    "    ax.legend()\n",
    "    plt.savefig(\"linear_regression.png\")\n",
    "\n",
    "    # Store loss function values at each iteration for linear data\n",
    "    loss_history_linear = []\n",
    "    rmse_history_linear = []\n",
    "    mae_history_linear = []\n",
    "\n",
    "    # Optimization process with recording loss values for linear data\n",
    "    def record_loss_linear(guess):\n",
    "        loss = mse_regression(guess, x_linear, y_linear)\n",
    "        rmse = rmse_regression(guess, x_linear, y_linear)\n",
    "        mae = mae_regression(guess, x_linear, y_linear)\n",
    "        loss_history_linear.append(loss)\n",
    "        rmse_history_linear.append(rmse)\n",
    "        mae_history_linear.append(mae)\n",
    "\n",
    "    minimize(mse_regression, initial_guess_linear, args=(x_linear, y_linear), method=method_linear, callback=record_loss_linear)\n",
    "\n",
    "    # Plot loss function value on iteration number for MSE (linear)\n",
    "    plt.figure()\n",
    "    plt.plot(range(len(loss_history_linear)), loss_history_linear, marker='o')\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel('MSE Loss (linear)')\n",
    "    plt.title('Loss Function on Iteration Number (linear)')\n",
    "    plt.savefig(\"Linear Regression MSE Loss\")\n",
    "\n",
    "    # Plot loss function value on iteration number for RMSE (linear)\n",
    "    plt.figure()\n",
    "    plt.plot(range(len(rmse_history_linear)), rmse_history_linear, marker='o')\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel('RMSE Loss (linear)')\n",
    "    plt.title('RMSE Loss on Iteration Number (linear)')\n",
    "    plt.savefig(\"Linear Regression RMSE Loss\")\n",
    "\n",
    "    # Plot loss function value on iteration number for MAE (linear)\n",
    "    plt.figure()\n",
    "    plt.plot(range(len(mae_history_linear)), mae_history_linear, marker='o')\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel('MAE Loss (linear)')\n",
    "    plt.title('MAE Loss on Iteration Number (linear)')\n",
    "    plt.savefig(\"Linear Regression MAE Loss\")\n",
    "\n",
    "    # Plot and investigate quadratic data\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    ax.plot(x_quadratic, y_quadratic, \"o\", label=\"data (quadratic)\")\n",
    "    ax.legend(loc=\"best\")\n",
    "\n",
    "    # Maximizing the probability for point to be from the distribution for quadratic data\n",
    "    results_quadratic = minimize(\n",
    "        mse_regression_quadratic,\n",
    "        initial_guess_quadratic,\n",
    "        args=(x_quadratic, y_quadratic,),\n",
    "        method=method_quadratic,\n",
    "        options={\"disp\": True}\n",
    "    )\n",
    "    print(\"Quadratic Regression Results:\")\n",
    "    print(results_quadratic)\n",
    "    print(\"Parameters (Quadratic): \", results_quadratic.x)\n",
    "\n",
    "    # Plot quadratic results\n",
    "    xx_quadratic = np.linspace(np.min(x_quadratic), np.max(x_quadratic), 100)\n",
    "    yy_quadratic = results_quadratic.x[0] * x_quadratic**2 + results_quadratic.x[1] * x_quadratic + results_quadratic.x[2]\n",
    "\n",
    "    ax.plot(x_quadratic, y_true_quadratic, \"g-\", label=\"True (quadratic)\")\n",
    "    ax.plot(xx_quadratic, yy_quadratic, \"m--.\", label=\"MLE (quadratic)\")\n",
    "    ax.legend()\n",
    "    plt.savefig(\"quadratic_regression.png\")\n",
    "\n",
    "    # Store loss function values at each iteration for quadratic data\n",
    "    loss_history_quadratic = []\n",
    "    rmse_history_quadratic = []\n",
    "    mae_history_quadratic = []\n",
    "\n",
    "    # Optimization process with recording loss values for quadratic data\n",
    "    def record_loss_quadratic(guess_quadratic):\n",
    "        loss = mse_regression_quadratic(guess_quadratic, x_quadratic, y_quadratic)\n",
    "        rmse = rmse_regression_quadratic(guess_quadratic, x_quadratic, y_quadratic)\n",
    "        mae = mae_regression_quadratic(guess_quadratic, x_quadratic, y_quadratic)\n",
    "        loss_history_quadratic.append(loss)\n",
    "        rmse_history_quadratic.append(rmse)\n",
    "        mae_history_quadratic.append(mae)\n",
    "\n",
    "    minimize(mse_regression_quadratic, initial_guess_quadratic, args=(x_quadratic, y_quadratic), method=method_quadratic, callback=record_loss_quadratic)\n",
    "\n",
    "    # Plot loss function value on iteration number for MSE (quadratic)\n",
    "    plt.figure()\n",
    "    plt.plot(range(len(loss_history_quadratic)), loss_history_quadratic, marker='o')\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel('MSE Loss (quadratic)')\n",
    "    plt.title('Loss Function on Iteration Number (quadratic)')\n",
    "    plt.savefig(\"Quadratic Regression MSE Loss\")\n",
    "\n",
    "    # Plot loss function value on iteration number for RMSE (quadratic)\n",
    "    plt.figure()\n",
    "    plt.plot(range(len(rmse_history_quadratic)), rmse_history_quadratic, marker='o')\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel('RMSE Loss (quadratic)')\n",
    "    plt.title('RMSE Loss on Iteration Number (quadratic)')\n",
    "    plt.savefig(\"Quadratic Regression RMSE Loss\")\n",
    "\n",
    "    # Plot loss function value on iteration number for MAE (quadratic)\n",
    "    plt.figure()\n",
    "    plt.plot(range(len(mae_history_quadratic)), mae_history_quadratic, marker='o')\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel('MAE Loss (quadratic)')\n",
    "    plt.title('MAE Loss on Iteration Number (quadratic)')\n",
    "    plt.savefig(\"Quadratic Regression MAE Loss\")\n",
    "    plt.show()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
